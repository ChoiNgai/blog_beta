(window.webpackJsonp=window.webpackJsonp||[]).push([[117],{498:function(t,a,s){"use strict";s.r(a);var n=s(30),e=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"flinksql流处理中的特殊概念"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#flinksql流处理中的特殊概念"}},[t._v("#")]),t._v(" FlinkSQL流处理中的特殊概念")]),t._v(" "),s("h2",{attrs:{id:"二、流处理中的特殊概念"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#二、流处理中的特殊概念"}},[t._v("#")]),t._v(" 二、流处理中的特殊概念")]),t._v(" "),s("p",[s("font",{attrs:{color:"Tomato"}},[t._v("Table API和SQL，本质上还是基于关系型表的操作方式；而关系型表、关系代数，以及SQL本身，一般是有界的，更适合批处理的场景。这就导致在进行流处理的过程中，理解会稍微复杂一些，需要引入一些特殊概念")])],1),t._v(" "),s("h3",{attrs:{id:"_2-1-流处理和关系代数-表-及sql-的区别"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-流处理和关系代数-表-及sql-的区别"}},[t._v("#")]),t._v(" 2.1 流处理和关系代数（表，及SQL）的区别")]),t._v(" "),s("table",[s("thead",[s("tr",[s("th"),t._v(" "),s("th",[t._v("关系代数（表）/SQL")]),t._v(" "),s("th",[t._v("流处理")])])]),t._v(" "),s("tbody",[s("tr",[s("td",[t._v("处理的数据对象")]),t._v(" "),s("td",[t._v("字段元组的有界集合")]),t._v(" "),s("td",[t._v("字段元组的无限序列")])]),t._v(" "),s("tr",[s("td",[t._v("查询（Query）对数据的访问")]),t._v(" "),s("td",[t._v("可以访问到完整的数据输入")]),t._v(" "),s("td",[t._v("无法访问所有数据，必须持续“等待”流式输入")])]),t._v(" "),s("tr",[s("td",[t._v("查询终止条件")]),t._v(" "),s("td",[t._v("生成固定大小的结果集后终止")]),t._v(" "),s("td",[t._v("永不停止，根据持续收到的数据不断更新查询结果")])])])]),t._v(" "),s("p",[t._v("        可以看到，其实关系代数（主要就是指关系型数据库中的表）和SQL，主要就是针对批处理的，这和流处理有天生的隔阂。\n        ")]),t._v(" "),s("h3",{attrs:{id:"_2-2-动态表-dynamic-tables"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-动态表-dynamic-tables"}},[t._v("#")]),t._v(" 2.2 动态表（Dynamic Tables）")]),t._v(" "),s("p",[t._v("        因为流处理面对的数据，是连续不断的，这和我们熟悉的关系型数据库中保存的“表”完全不同。所以，"),s("strong",[t._v("如果我们把流数据转换成Table，然后执行类似于table的 select 操作，结果就不是一成不变的，而是随着新数据的到来，会不停更新")]),t._v("。")]),t._v(" "),s("p",[s("font",{attrs:{color:"\t\tTomato"}},[t._v("我们可以随着新数据的到来，不停地在之前的基础上更新结果。这样得到的表，在Flink Table API  概念里，就叫做 “动态表” （Dynamic Tables）")])],1),t._v(" "),s("p",[s("strong",[t._v("动态表是 Flink 对流数据的 Table API 和 SQL 支持的核心概念")]),t._v("。与表示批处理数据的静态表不同，动态表是随时间变化的。动态表可以像静态的批处理表一样进行查询，查询一个动态表会产生持续查询（Continuous Query）。"),s("strong",[t._v("连续查询永远不会终止，并会生成另一个动态表。查询（Query）会不断更新其动态结果表，以反映其动态输入表上的更改")]),t._v("。\n        ")]),t._v(" "),s("h3",{attrs:{id:"_2-3-流式持续查询的过程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-流式持续查询的过程"}},[t._v("#")]),t._v(" 2.3 流式持续查询的过程")]),t._v(" "),s("p",[t._v("        下图显示了流、动态表和连续查询的关系：\n"),s("img",{attrs:{src:"https://img-blog.csdnimg.cn/20210117101717553.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDMxODgzMA==,size_16,color_FFFFFF,t_70",alt:"在这里插入图片描述"}})]),t._v(" "),s("p",[t._v("        流式持续查询的过程为：")]),t._v(" "),s("ol",[s("li",[t._v("流被转换为动态表")]),t._v(" "),s("li",[t._v("对动态表计算连续查询，生成新的动态表")]),t._v(" "),s("li",[t._v("生成的动态表被转换回流")])]),t._v(" "),s("h4",{attrs:{id:"_2-3-1-将流转换成表-table"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-1-将流转换成表-table"}},[t._v("#")]),t._v(" 2.3.1 将流转换成表（Table）")]),t._v(" "),s("p",[s("strong",[t._v("为了处理带有关系查询的流，必须先将其转换为表")])]),t._v(" "),s("p",[t._v("        从概念上讲，流的每个数据记录，都被解释为对结果表的插入（Insert）修改。因为流是持续不断的，而且之前的输出结果无法改变。本质上，我们其实是从一个、只有插入操作的 changelog（更新日志）流，来构建一个表")]),t._v(" "),s("p",[t._v("        为了更好地说明动态表和持续查询的概念，我们来举一个具体的例子")]),t._v(" "),s("p",[t._v("        比如，我们现在的输入数据，就是用户在网站上的访问行为，数据类型（Schema）如下：")]),t._v(" "),s("div",{staticClass:"language-json extra-class"},[s("pre",{pre:!0,attrs:{class:"language-json"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n  user"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("  VARCHAR"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 用户名")]),t._v("\n  cTime"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" TIMESTAMP"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 访问某个URL的时间戳")]),t._v("\n  url"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v("   VARCHAR    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 用户访问的URL")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),s("p",[t._v("        下图显示了如何将访问URL事件流，或者叫点击事件流（左侧）转换为表（右侧）。\n        ")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://img-blog.csdnimg.cn/20210117101916237.png#pic_center",alt:"在这里插入图片描述"}}),t._v("\n        随着插入更多的访问事件流记录，生成的表将不断增长。\n        ")]),t._v(" "),s("h4",{attrs:{id:"_2-3-2-持续查询-continuous-query"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-2-持续查询-continuous-query"}},[t._v("#")]),t._v(" 2.3.2 持续查询（Continuous Query）")]),t._v(" "),s("p",[t._v("        持续查询，会在动态表上做计算处理，并作为结果生成新的动态表。与批处理查询不同，连续查询从不终止，并根据输入表上的更新更新其结果表。")]),t._v(" "),s("p",[t._v("        在任何时间点，连续查询的结果在语义上，等同于在输入表的快照上，以批处理模式执行的同一查询的结果。")]),t._v(" "),s("p",[t._v("        在下面的示例中，我们展示了对点击事件流中的一个持续查询。")]),t._v(" "),s("p",[t._v("        这个Query很简单，是一个分组聚合做 count 统计的查询。它将用户字段上的 clicks 表分组，并统计访问的 url 数。图中显示了随着时间的推移，当 clicks 表被其他行更新时如何计算查询。")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://img-blog.csdnimg.cn/20210117102140746.png?,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDMxODgzMA==,size_16,color_FFFFFF,t_70#pic_center",alt:""}})]),t._v(" "),s("h4",{attrs:{id:"_2-3-3-将动态表转换成流"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-3-将动态表转换成流"}},[t._v("#")]),t._v(" 2.3.3 将动态表转换成流")]),t._v(" "),s("p",[t._v("        与常规的数据库表一样，动态表可以通过插入（Insert）、更新（Update）和删除（Delete）更改，进行持续的修改。"),s("font",{attrs:{color:"\tTomato"}},[t._v("将动态表转换为流或将其写入外部系统时，需要对这些更改进行编码")]),t._v("。Flink的Table API和SQL支持三种方式对动态表的更改进行编码：")],1),t._v(" "),s("ul",[s("li",[s("strong",[t._v("仅追加（Append-only）流")])])]),t._v(" "),s("p",[t._v("        仅通过插入（Insert）更改，来修改的动态表，可以直接转换为“仅追加”流。这个流中发出的数据，就是动态表中新增的每一行。")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("撤回（Retract）流")])])]),t._v(" "),s("p",[t._v("        Retract流是包含两类消息的流，添加（Add）消息和撤回（Retract）消息。")]),t._v(" "),s("p",[t._v("        动态表通过将 INSERT 编码为 add 消息、DELETE 编码为retract消息、UPDATE 编码为被更改行（前一行）的 retract 消息和更新后行（新行）的 add 消息，转换为 retract 流。")]),t._v(" "),s("p",[t._v("        下图显示了将动态表转换为 Retract 流的过程。")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://img-blog.csdnimg.cn/20210117102643561.png?,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDMxODgzMA==,size_16,color_FFFFFF,t_70",alt:"在这里插入图片描述"}})]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("Upsert（更新插入）流")])])]),t._v(" "),s("p",[t._v("        Upsert 流包含两种类型的消息：Upsert 消息和 delete 消息。转换为 upsert 流的动态表，需要有唯一的键（key）。")]),t._v(" "),s("p",[t._v("        通过将 INSERT 和 UPDATE 更改编码为 upsert 消息，将DELETE更改编码为DELETE消息，就可以将具有唯一键（Unique Key）的动态表转换为流。")]),t._v(" "),s("p",[t._v("        下图显示了将动态表转换为 upsert 流的过程。")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://img-blog.csdnimg.cn/2021011710302610.png?,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDMxODgzMA==,size_16,color_FFFFFF,t_70",alt:"在这里插入图片描述"}})]),t._v(" "),s("p",[t._v("​          这些概念我们之前都已提到过。需要注意的是，在代码里将动态表转换为DataStream时，仅支持 Append 和Retract流 。而向外部系统输出动态表的TableSink接口，则可以有不同的实现，比如之前我们讲到的ES，就可以有Upsert模式。")]),t._v(" "),s("h3",{attrs:{id:"_2-4-时间特性"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-时间特性"}},[t._v("#")]),t._v(" 2.4 时间特性")]),t._v(" "),s("p",[t._v("        基于时间的操作（比如 Table API 和 SQL 中窗口操作），需要定义相关的时间语义和时间数据来源的信息。所以，"),s("strong",[t._v("Table可以提供一个逻辑上的时间字段，用于在表处理程序中，指示时间和访问相应的时间戳")]),t._v("。")]),t._v(" "),s("p",[t._v("        时间属性，可以是每个表 schema 的一部分。一旦定义了时间属性，它就可以作为一个字段引用，并且可以在基于时间的操作中使用。")]),t._v(" "),s("p",[t._v("        时间属性的行为类似于常规时间戳，可以访问，并且进行计算。")]),t._v(" "),s("h4",{attrs:{id:"_2-4-1-处理时间-processing-time"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-1-处理时间-processing-time"}},[t._v("#")]),t._v(" 2.4.1 处理时间（Processing Time）")]),t._v(" "),s("p",[t._v("        处理时间语义下，允许表处理程序根据机器的本地时间生成结果。它是时间的最简单概念。它既不需要提取时间戳，也不需要生成watermark。")]),t._v(" "),s("p",[t._v("        定义处理时间属性有三种方法：在 DataStream 转化时直接指定；在定义 Table Schema 时指定；在创建表的 DDL 中指定。")]),t._v(" "),s("h5",{attrs:{id:"_2-4-1-1-datastream转化成table时指定"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-1-1-datastream转化成table时指定"}},[t._v("#")]),t._v(" 2.4.1.1 DataStream转化成Table时指定")]),t._v(" "),s("p",[t._v("        由 DataStream 转换成表时，可以在后面指定字段名来定义Schema。在定义 Schema 期间，可以使用 "),s("code",[t._v(".proctime")]),t._v(" ，定义处理时间字段。")]),t._v(" "),s("p",[t._v("        注意，这个 proctime 属性只能通过附加逻辑字段，来扩展物理schema 。因此，只能在 schema 定义的末尾定义它。")]),t._v(" "),s("p",[t._v("        代码如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 定义好 DataStream")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" inputStream"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" env"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("readTextFile"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\sensor.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dataStream"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("SensorReading"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" inputStream\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dataArray "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('","')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    SensorReading"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataArray"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataArray"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toLong"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataArray"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDouble"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 将 DataStream转换为 Table，并指定时间字段")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sensorTable "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fromDataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'id, '")]),t._v("temperature"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'timestamp, '")]),t._v("pt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("proctime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h5",{attrs:{id:"_2-4-1-2-定义table-schema-时指定"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-1-2-定义table-schema-时指定"}},[t._v("#")]),t._v(" 2.4.1.2 定义Table Schema 时指定")]),t._v(" "),s("p",[t._v("        这种方法其实也很简单，只要在定义 Schema 的时候，加上一个新的字段，并指定成 proctime 就可以了。")]),t._v(" "),s("p",[t._v("        代码如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[t._v("tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("connect"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" FileSystem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"..\\\\sensor.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withFormat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withSchema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Schema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("STRING"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"timestamp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("BIGINT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temperature"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DOUBLE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"pt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("TIMESTAMP"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("proctime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 指定 pt字段为处理时间")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 定义表结构")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTemporaryTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"inputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建临时表")]),t._v("\n")])])]),s("h5",{attrs:{id:"_2-4-1-3-创建表的ddl中指定"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-1-3-创建表的ddl中指定"}},[t._v("#")]),t._v(" 2.4.1.3 创建表的DDL中指定")]),t._v(" "),s("p",[t._v("        在创建表的DDL中，增加一个字段并指定成 proctime，也可以指定当前的时间字段。")]),t._v(" "),s("p",[t._v("        代码如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sinkDDL"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("\"\"\"\n    |create table dataTable (\n    |  id varchar(20) not null,\n    |  ts bigint,\n    |  temperature double,\n    |  pt AS PROCTIME()\n    |) with (\n    |  'connector.type' = 'filesystem',\n    |  'connector.path' = 'file:///D:\\\\..\\\\sensor.txt',\n    |  'format.type' = 'csv'\n    |)\n  \"\"\"")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stripMargin\n\ntableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqlUpdate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sinkDDL"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 执行 DDL")]),t._v("\n")])])]),s("p",[s("font",{attrs:{color:"red"}},[t._v("注意：运行这段DDL，必须使用Blink Planner")])],1),t._v(" "),s("h4",{attrs:{id:"_2-4-2-事件时间-event-time"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-2-事件时间-event-time"}},[t._v("#")]),t._v(" 2.4.2 事件时间（Event Time）")]),t._v(" "),s("p",[s("strong",[t._v("事件时间语义，允许表处理程序根据每个记录中包含的时间生成结果")]),t._v("。这样即使在有乱序事件或者延迟事件时，也可以获得正确的结果。")]),t._v(" "),s("p",[t._v("        为了处理无序事件，并区分流中的准时和迟到事件；Flink需要从事件数据中，提取时间戳，并用来推进事件时间的进展（watermark）。")]),t._v(" "),s("h5",{attrs:{id:"_2-4-2-1-datastream转化成table时指定"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-2-1-datastream转化成table时指定"}},[t._v("#")]),t._v(" 2.4.2.1 DataStream转化成Table时指定")]),t._v(" "),s("p",[t._v("        在 DataStream 转换成 Table，schema 的定义期间，使用 .rowtime 可以定义事件时间属性。注意，"),s("font",{attrs:{color:"\tTomato"}},[t._v("必须在转换的数据流中分配时间戳和watermark")])],1),t._v(" "),s("p",[t._v("        在将数据流转换为表时，有两种定义时间属性的方法。根据指定的 "),s("code",[t._v(".rowtime")]),t._v(" 字段名是否存在于数据流的架构中，timestamp 字段可以：")]),t._v(" "),s("ul",[s("li",[t._v("作为新字段追加到schema")]),t._v(" "),s("li",[t._v("替换现有字段")])]),t._v(" "),s("p",[t._v("        在这两种情况下，定义的事件时间戳字段，都将保存 DataStream 中事件时间戳的值。")]),t._v(" "),s("p",[t._v("        代码如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" inputStream"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" env"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("readTextFile"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\sensor.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dataStream"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("SensorReading"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" inputStream\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dataArray "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('","')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        SensorReading"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataArray"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataArray"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toLong"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataArray"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDouble"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("assignAscendingTimestamps"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("timestamp "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000L")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 将 DataStream转换为 Table，并指定时间字段")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sensorTable "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fromDataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'id, '")]),t._v("timestamp"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rowtime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token symbol"}},[t._v("'temperature")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 或者，直接追加字段")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sensorTable2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fromDataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'id, '")]),t._v("temperature"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'timestamp, '")]),t._v("rt"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rowtime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h5",{attrs:{id:"_2-4-2-2-定义table-schema时指定"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-2-2-定义table-schema时指定"}},[t._v("#")]),t._v(" 2.4.2.2 定义Table Schema时指定")]),t._v(" "),s("p",[t._v("        这种方法只要在定义 Schema 的时候，将事件时间字段，并指定成 "),s("code",[t._v("rowtime")]),t._v(" 就可以了。")]),t._v(" "),s("p",[t._v("        代码如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[t._v("tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("connect"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" FileSystem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sensor.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withFormat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withSchema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Schema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("STRING"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"timestamp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("BIGINT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("rowtime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Rowtime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("timestampsFromField"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"timestamp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 从字段中提取时间戳")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("watermarksPeriodicBounded"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1000")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// watermark 延迟 1 秒 )")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temperature"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DOUBLE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 定义表结构")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTemporaryTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"inputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建临时表")]),t._v("\n")])])]),s("h5",{attrs:{id:"_2-4-3-创建表的-ddl-中指定"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-3-创建表的-ddl-中指定"}},[t._v("#")]),t._v(" 2.4.3 创建表的 DDL 中指定")]),t._v(" "),s("p",[s("font",{attrs:{color:"Tomato"}},[t._v("事件时间属性，是使用 watermark 语句，定义现有事件时间字段上的 watermark 生成表达式，该表达式将事件时间字段标记为事件时间属性")])],1),t._v(" "),s("p",[t._v("        代码如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sinkDDL"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("\"\"\"\n|create table dataTable (\n|  id varchar(20) not null,\n|  ts bigint,\n|  temperature double,\n|  rt AS TO_TIMESTAMP( FROM_UNIXTIME(ts) ),\n|  watermark for rt as rt - interval '1' second\n|) with (\n|  'connector.type' = 'filesystem',\n|  'connector.path' = 'file:///D:\\\\..\\\\sensor.txt',\n|  'format.type' = 'csv'\n|)\n\"\"\"")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stripMargin\ntableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqlUpdate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sinkDDL"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 执行 DDL")]),t._v("\n")])])]),s("p",[t._v("        这里 "),s("code",[t._v("FROM_UNIXTIME")]),t._v(" 是系统内置的时间函数，用来将一个整数（秒数）转换成“"),s("code",[t._v("YYYY-MM-DD hh:mm:ss")]),t._v("”格式（默认，也可以作为第二个String参数传入）的日期时间字符串（date time string）；然后再用"),s("code",[t._v("TO_TIMESTAMP")]),t._v("将其转换成"),s("code",[t._v("Timestamp")])]),t._v(" "),s("h2",{attrs:{id:"ref"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#ref"}},[t._v("#")]),t._v(" Ref")]),t._v(" "),s("blockquote",[s("p",[t._v("1、http://www.atguigu.com/\n2、https://www.bilibili.com/video/BV12k4y1z7LM?from=search&seid=953051020130358915\n3、https://blog.csdn.net/u013411339/article/details/93267838")])]),t._v(" "),s("blockquote",[s("p",[t._v("tips："),s("strong",[t._v("学习时间语义，要配合窗口操作才能发挥作用")])])])])}),[],!1,null,null,null);a.default=e.exports}}]);