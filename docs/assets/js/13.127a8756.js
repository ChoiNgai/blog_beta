(window.webpackJsonp=window.webpackJsonp||[]).push([[13],{409:function(a,t,s){"use strict";s.r(t);var e=s(30),_=Object(e.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h1",{attrs:{id:"hdfs的文件管理和容错"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hdfs的文件管理和容错"}},[a._v("#")]),a._v(" HDFS的文件管理和容错")]),a._v(" "),s("h2",{attrs:{id:"hdfs-文件管理"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hdfs-文件管理"}},[a._v("#")]),a._v(" HDFS 文件管理")]),a._v(" "),s("h3",{attrs:{id:"_1、hdfs-的块分布"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1、hdfs-的块分布"}},[a._v("#")]),a._v(" 1、HDFS 的块分布")]),a._v(" "),s("p",[a._v("        HDFS 会将数据文件切分成一个个小的数据块进行存储，同时会将这些数据块的副本保存多份，分别保存到不同的 DataNode 上。HDFS 中数据块的副本数由 "),s("code",[a._v("hdfs-site.xml")]),a._v("文件中的"),s("code",[a._v("dfs.replication")]),a._v("属性决定，配置属性如下：")]),a._v(" "),s("div",{staticClass:"language-xml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-xml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n         "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("dfs.replication"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("name")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n         "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("<")]),a._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("3"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("value")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("</")]),a._v("property")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(">")])]),a._v("\n")])])]),s("p",[a._v("        Hadoop 默认的副本数为3，并且在机架的存放上也有一定的"),s("strong",[a._v("策略")]),a._v("。Hadoop 的默认布局策略，即默认的"),s("strong",[a._v("副本存放策略")]),a._v("如下：")]),a._v(" "),s("p",[a._v("        （1）第 1 个副本存放在 HDFS 客户端所在的节点上。")]),a._v(" "),s("p",[a._v("        （2）第 2 个副本存放在与第1个副本不同的机架上，并且是随机选择的节点。")]),a._v(" "),s("p",[a._v("        （3）第 3 个副本存放在与第2个副本相同的机架上，并且是不同的节点。")]),a._v(" "),s("h3",{attrs:{id:"_2、数据读取"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2、数据读取"}},[a._v("#")]),a._v(" 2、数据读取")]),a._v(" "),s("p",[a._v("        HDFS 的数据读取过程需要客户端先访问 NameNode，获取元数据信息，然后到具体的 DataNode 上读取数据，如下图所示：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://img-blog.csdnimg.cn/20210306175744121.png?,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDMxODgzMA==,size_16,color_FFFFFF,t_70",alt:""}})]),a._v(" "),s("p",[a._v("​      （1）"),s("strong",[a._v("客户端向NameNode发起请求，读取元数据信息")]),a._v("。"),s("font",{attrs:{color:"tomato"}},[s("strong",[a._v("NameNode上存储着整个HDFS集群的元数据信息")])]),a._v("，这些元数据信息包括"),s("font",{attrs:{color:"tomato"}},[s("strong",[a._v("文件名，所有者，所在组，权限，数据块和 DataNode列表")])]),a._v("。")],1),a._v(" "),s("p",[a._v("        这个过程中还要对客户端的身份信息进行"),s("strong",[a._v("验证")]),a._v("，同时检测是否存在要读取的文件，并且需要验证客户端的身份是否具有"),s("strong",[a._v("访问权限")]),a._v("。")]),a._v(" "),s("p",[a._v("        （2）"),s("strong",[a._v("NameNode 将相关的元数据信息返回给客户端")]),a._v("。")]),a._v(" "),s("p",[a._v("        （3）"),s("strong",[a._v("客户端到指定的 DataNode 上读取相应的数据块")]),a._v("。")]),a._v(" "),s("p",[a._v("        （4）"),s("strong",[a._v("DataNode 返回相应的数据块信息")]),a._v("。")]),a._v(" "),s("p",[a._v("        第（3）和（4）步会持续进行，一直到文件的所有数据块都读取完毕或者 HDFS 客户端主动关闭了文件流为止。")]),a._v(" "),s("h3",{attrs:{id:"_3、数据写入"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3、数据写入"}},[a._v("#")]),a._v(" 3、数据写入")]),a._v(" "),s("p",[a._v("        HDFS 中的数据写入过程同样需要客户端先访问 NameNode，获取元数据信息，然后到具体的 DataNode 上写入数据，如图所示")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://img-blog.csdnimg.cn/20210308001223267.png?,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDMxODgzMA==,size_16,color_FFFFFF,t_70",alt:""}})]),a._v(" "),s("p",[a._v("        以下是具体步骤：")]),a._v(" "),s("p",[a._v("        （1）客户端请求 NameNode 获取元数据信息。这个过程中，NameNode 要对客户端的省份信息进行验证，同时需要"),s("strong",[a._v("验证")]),a._v("客户端的身份是否具有"),s("strong",[a._v("写权限")]),a._v("。")]),a._v(" "),s("p",[a._v("        （2）"),s("strong",[a._v("NameNode 返回相应的元数据信息给客户端")]),a._v("。")]),a._v(" "),s("p",[a._v("        （3）"),s("strong",[a._v("客户端向第一个 DataNode 写数据")]),a._v("。")]),a._v(" "),s("p",[a._v("        （4）"),s("strong",[a._v("第 1 个 DataNode 向第 2 个 DataNode 写数据")]),a._v("。")]),a._v(" "),s("p",[a._v("        （5）"),s("strong",[a._v("第 2 个 DataNode 向第 3 个 DataNode 写数据")]),a._v("。")]),a._v(" "),s("p",[a._v("        （6）"),s("strong",[a._v("第 3 个 DataNode 向第 2 个 DataNode 返回确认结果信息")]),a._v("。")]),a._v(" "),s("p",[a._v("        （7）"),s("strong",[a._v("第 2 个 DataNode 向第 1 个 DataNode 返回确认结果信息")]),a._v("。")]),a._v(" "),s("p",[a._v("        （8）"),s("strong",[a._v("第 1 个 DataNode 向客户端返回确认结果信息")]),a._v("。")]),a._v(" "),s("p",[a._v("        其中，第（4）步和第（5）步是异步执行的，当 HDFS 中的多个 DataNode 发生故障或者发生错误时，只要正确写入了满足最少数目要求的数据副本数，HDFS客户端就可以从数据块的副本中恢复数据。")]),a._v(" "),s("p",[a._v("        最少数目要求的数据副本数由"),s("code",[a._v("hdfs-site.xml")]),a._v("文件中的"),s("code",[a._v("dfs.namenode.replication.min")]),a._v("属性决定，配置属性如下：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n         "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("dfs.namenode.replication.min"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n         "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token operator"}},[s("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[a._v("1")]),a._v("<")]),a._v("/value"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n")])])]),s("p",[s("strong",[a._v("最少数目要求的数据副本数默认为1，即只要正确写入了数据的一个副本，客户端就可以从数据副本中恢复数据")]),a._v("。")]),a._v(" "),s("h3",{attrs:{id:"_4、数据完整性"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4、数据完整性"}},[a._v("#")]),a._v(" 4、数据完整性")]),a._v(" "),s("p",[a._v("        通常，在校验数据是否损坏时可以用如下方式。")]),a._v(" "),s("p",[a._v("        （1）当数据"),s("strong",[a._v("第一次引入时")]),a._v("，计算"),s("strong",[a._v("校验和")]),a._v("，")]),a._v(" "),s("p",[a._v("        （2）当数据经过一系列的"),s("strong",[a._v("传输或者复制时")]),a._v("，再次"),s("strong",[a._v("计算校验和")]),a._v("。")]),a._v(" "),s("p",[a._v("        （3）对比第（1）和第（2）步的校验和是否一致，如果两次数据的校验和不一致，则证明数据已经被破坏。")]),a._v(" "),s("blockquote",[s("p",[s("strong",[a._v("注意：这种使用校验和来验证数据的技术只能检测数据是否被损坏，并不能修复数据。")])])]),a._v(" "),s("p",[a._v("        HDFS中校验数据是否损坏使用的也是校验和技术，无论是进行数据的写入还是进行数据的读取，都会验证数据的校验和。校验和的字节数由"),s("code",[a._v("core-site.xml")]),a._v("文件中的"),s("code",[a._v("io.bytes.per.checksum")]),a._v("属性指定，默认的字节长度为 512 B，具体配置如下：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n         "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("io.bytes.per.checksum"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n         "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("value"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("51")]),s("span",{pre:!0,attrs:{class:"token operator"}},[s("span",{pre:!0,attrs:{class:"token file-descriptor important"}},[a._v("2")]),a._v("<")]),a._v("/value"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("/property"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n")])])]),s("p",[s("strong",[a._v("当 HDFS 写数据时")]),a._v("，HDFS 客户端会将"),s("strong",[a._v("要写入的数据及对应数据的校验和")]),a._v("发送到 DataNode 组成的复制管道中，其中最后一个 DataNode 负责验证数据的校验和是否一致。"),s("strong",[a._v("如果检测到校验和与 HDFS 客户端发送的校验和不一致，则 HDFS 客户端 会收到校验和异常的信息，可以在程序中捕获到这个异常，进行相应的处理，如重新写入数据或者用其他方式处理")]),a._v("。")]),a._v(" "),s("p",[a._v("        H"),s("strong",[a._v("DFS 读数据时")]),a._v("也会验证校验和，此时会将它们"),s("strong",[a._v("与 DataNode 中存储的校验和进行比较")]),a._v("。如果其与 DataNode 中存储的校验和不一致，则说明数据已经损坏，需要重新从其他 DataNode 读取数据。其中，"),s("strong",[a._v("每个 DataNode 都会保存一个校验和日志，客户端成功验证一个数据块之后，DataNode会更新该校验和日志")]),a._v("。")]),a._v(" "),s("p",[a._v("        除此之外，"),s("strong",[a._v("每个 DataNode 也会在后台运行一个扫描器（DataBlockScanner），定期验证存储在这个 DataNode 上的所有数据块")]),a._v("。")]),a._v(" "),s("p",[a._v("        由于 "),s("strong",[a._v("HDFS")]),a._v(" 提供的"),s("strong",[a._v("数据块副本机制")]),a._v("，"),s("strong",[a._v("当一个数据块损坏时，HDFS 能够自动复制其他完好的数据块来修复损坏的数据块")]),a._v("，得到一个新的，完好的数据块，以达到系统设置的副本数要求，因此在某些数据块出现损坏时，保证了数据的完整性。")]),a._v(" "),s("h3",{attrs:{id:"_5、-hdfs-容错"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5、-hdfs-容错"}},[a._v("#")]),a._v(" 5、 HDFS 容错")]),a._v(" "),s("p",[a._v("        HDFS 的容错机制大体上可以分为两个方面：文件系统的容错和 Hadoop 自身的容错。")]),a._v(" "),s("h4",{attrs:{id:"_5-1-文件系统的容错"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-1-文件系统的容错"}},[a._v("#")]),a._v(" 5.1 文件系统的容错")]),a._v(" "),s("p",[a._v("        文件系统的容错可以通过 NameNode 高可用、SecondaryNameNode 机制、数据块副本机制和心跳机制来实现。")]),a._v(" "),s("blockquote",[s("p",[s("strong",[a._v("注意：当以本地模式或者伪集群模式部署 Hadoop 时，会存在 SeconddayNameNode；当以集群模式部署 Hadoop 时，如果配置了 NameNode 的 HA 机制，则不会存在 SecondaryNameNode，此时会存在备 NameNode")]),a._v("。")])]),a._v(" "),s("p",[a._v("        在这里重点说下集群模式下 HDFS 的容错，有关 SecondaryNameNode 机制可参见上一篇文章《"),s("a",{attrs:{href:"https://alice.blog.csdn.net/article/details/114212487",target:"_blank",rel:"noopener noreferrer"}},[a._v("前方高能 | HDFS 的架构，你吃透了吗？"),s("OutboundLink")],1),a._v("》的说明：")]),a._v(" "),s("p",[a._v("        HDFS 的容错机制如图所示：")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://img-blog.csdnimg.cn/20210305193259274.png?,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDMxODgzMA==,size_16,color_FFFFFF,t_70",alt:""}}),a._v("\n        具体的流程如下：")]),a._v(" "),s("p",[a._v("        （1）备 NameNode 实时备份主 NameNode 上的元数据信息，一旦主 NameNode 发生故障不可用，则备 NameNode 迅速接管主 NameNode 的工作。")]),a._v(" "),s("p",[a._v("        （2）客户端向 NameNode 读取元数据信息。")]),a._v(" "),s("p",[a._v("        （3）NameNode 向客户端返回元数据信息。")]),a._v(" "),s("p",[a._v("        （4）客户端向 DataNode 读取/写入 数据，此时会分为读取数据和写入数据两种情况。")]),a._v(" "),s("p",[a._v("        ① 读取数据：HDFS 会检测文件块的完整性，确认文件块的"),s("strong",[a._v("检验和")]),a._v("是否一致，如果不一致，则从其他的 DataNode 上获取相应的副本。")]),a._v(" "),s("p",[a._v("        ② 写入数据：HDFS 会检测文件块的完整性，同时记录新创建的文件的所有文件块的"),s("strong",[a._v("校验和")]),a._v("。")]),a._v(" "),s("p",[a._v("        （5）\t"),s("strong",[a._v("DataNode 会定期向 NameNode 发送心跳信息，将自身节点的状态告知 NameNode")]),a._v("；"),s("strong",[a._v("NameNode 会将 DataNode 需要执行的命令放入心跳信息的返回结果中，返回给 DataNode 执")]),a._v("行。")]),a._v(" "),s("p",[s("strong",[a._v("当 DataNode 发生故障没有正常发送心跳信息时，NameNode 会检测文件块的副本数是否小于 系统设置值，如果小于设置值，则自动复制新的副本并分发到其他的 DataNode 上")]),a._v("。")]),a._v(" "),s("p",[a._v("        （6）集群中有数据关联的 DataNode 之间复制数据副本。")]),a._v(" "),s("p",[a._v("        当集群中的 DataNode 发生故障而失效，或者在集群中添加新的 DataNode 时，可能会导致"),s("strong",[a._v("数据分布不均匀")]),a._v("。"),s("strong",[a._v("当某个 DataNode 上的空闲空间资源大于系统设置的临界值时，HDFS 就会从 其他的 DataNode 上将数据迁移过来")]),a._v("。相对地，"),s("strong",[a._v("如果某个 DataNode 上的资源出现超负荷运载，HDFS 就会根据一定的规则寻找有空闲资源的 DataNode，将数据迁移过去")]),a._v("。")]),a._v(" "),s("p",[a._v("        还有一种从侧面说明 HDFS 支持容错的机制，即当"),s("strong",[a._v("从 HDFS 中删除数据时，数据并不是马上就会从 HDFS 中被删除，而是会将这些数据放到“回收站”目录中，随时可以恢复，直到超过了一定的时间才会真正删除这些数据")]),a._v("。")]),a._v(" "),s("h4",{attrs:{id:"_5-2-hadoop自身的容错"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-2-hadoop自身的容错"}},[a._v("#")]),a._v(" 5.2 Hadoop自身的容错")]),a._v(" "),s("p",[a._v("        Hadoop 自身的容错理解起来比较简单，当升级 Hadoop 系统时，如果出现 Hadoop 版本不兼容的问题，可以通过"),s("strong",[a._v("回滚 Hadoop 版本的方式")]),a._v("来实现自身的容错。")]),a._v(" "),s("h3",{attrs:{id:"_6、通过命令行管理文件"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_6、通过命令行管理文件"}},[a._v("#")]),a._v(" 6、通过命令行管理文件")]),a._v(" "),s("p",[a._v("        这部分内容在之前的文章中已经介绍，大概常用的有40个命令，详情👉"),s("a",{attrs:{href:"https://blog.csdn.net/weixin_44318830/article/details/112752525?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522161502761316780264016467%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=161502761316780264016467&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v1~rank_blog_v1-1-112752525.pc_v1_rank_blog_v1&utm_term=%E5%91%BD%E4%BB%A4",target:"_blank",rel:"noopener noreferrer"}},[a._v("干货 | HDFS常用的40个命令，你都知道吗？\n"),s("OutboundLink")],1)]),a._v(" "),s("h2",{attrs:{id:"ref"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#ref"}},[a._v("#")]),a._v(" Ref")]),a._v(" "),s("blockquote",[s("p",[a._v("1、《海量数据处理与大数据技术实践》\n2、《大数据平台架构与原型实现》\n3、https://www.cnblogs.com/mayundalao/p/11799849.html")])])])}),[],!1,null,null,null);t.default=_.exports}}]);