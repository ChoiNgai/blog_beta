(window.webpackJsonp=window.webpackJsonp||[]).push([[22],{416:function(t,e,a){"use strict";a.r(e);var n=a(30),l=Object(n.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h2",{attrs:{id:"hive使用必知必会系列"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hive使用必知必会系列"}},[t._v("#")]),t._v(" Hive使用必知必会系列")]),t._v(" "),a("h2",{attrs:{id:"一、hive的几种数据模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一、hive的几种数据模型"}},[t._v("#")]),t._v(" "),a("strong",[t._v("一、Hive的几种数据模型")])]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("内部表")]),t._v(" (Table 将数据保存到Hive 自己的数据仓库目录中：/usr/hive/warehouse)")]),t._v(" "),a("li",[a("strong",[t._v("外部表")]),t._v(" (External Table 相对于内部表，数据不在自己的数据仓库中，只保存数据的元信息)")]),t._v(" "),a("li",[a("strong",[t._v("分区表")]),t._v(" (Partition Table将数据按照设定的条件分开存储，提高查询效率，分区-----\x3e  目录)")]),t._v(" "),a("li",[a("strong",[t._v("桶表")]),t._v(" (Bucket Table本质上也是一种分区表，类似 hash 分区  桶 ----\x3e 文件)")]),t._v(" "),a("li",[a("strong",[t._v("视图表")]),t._v(" (视图表是一个虚表，不存储数据，用来简化复杂的查询)")])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("注意:内部表删除表后数据也会删除，外部表数据删除后不会从hdfs中删除\n")])])]),a("h3",{attrs:{id:""}},[a("a",{staticClass:"header-anchor",attrs:{href:"#"}},[t._v("#")]),t._v(" ** **")]),t._v(" "),a("h3",{attrs:{id:"_1-内部表-管理表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-内部表-管理表"}},[t._v("#")]),t._v(" "),a("strong",[t._v("1. 内部表/管理表")])]),t._v(" "),a("p",[t._v("**\n**")]),t._v(" "),a("ul",[a("li",[t._v("每一个Table在Hive中都有一个相应的目录存储数据")]),t._v(" "),a("li",[t._v("所有的Table数据都存储在该目录")])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("# 创建表\ncreate table if not exists aiops.appinfo (\n    appname string,\n    level string,\n    leader string,\n    appline string,\n    dep string,\n    ips  array<string>)\n    ROW FORMAT DELIMITED\n    FIELDS TERMINATED BY ' '\n    COLLECTION ITEMS TERMINATED BY ',';\n\n# 自定义文件和记录格式\n## 使用create table创建表，最后使用stored as sequencefile保存成sequence格式[默认是text格式]\n\n# 数据库授权\nhive> grant create on database dbname to user hadoop;\n\n# 导入数据(本地导入和hdfs导入)\nhive> load data inpath  'hdfs://hdfs-name/sure.csv' overwrite into table aiops.appinfo;\nload data local inpath '/home/hdfs/online_state1' overwrite into table online_state PARTITION (end_dt='99991231');\n\n# 查看表结构\nhive> describe extended bgops;\nhive> describe bgops;\n\n# 修改列名\n## 这个命令可以修改表的列名，数据类型，列注释和列所在的位置顺序，FIRST将列放在第一列，AFTER col_name将列放在col_name后面一列\nhive> ALTER TABLE aiops.appinfo CHANGE hostnum ipnum int comment 'some 注释' AFTER col3;\n\n# 修改表结构\nALTER TABLE aiops.appinfo replace columns (appname string,level string,leader string,appline string,dep string,ips array<string>);\nALTER TABLE appinfo replace columns (appname string,appline string,level string,leader string,dep string,idcnum int,idcs array<string>,hostnum int,ips array<string>);\n## 增加表的列字段(默认增加到最后一列，可以使用change column 来调整位置)\nhive> alter table appinfo add columns (appclass string comment 'app_perf_class');\n\n# 导出表查询结果(会将结果导出到testoutput目录下)\nhive> insert overwrite local directory './testoutput'\n    > row format delimited fields terminated by \"\\t\"\n    > select ip,appname,leader from appinfo  LATERAL VIEW explode(ips) tmpappinfo  AS ip;\n")])])]),a("p",[a("strong",[t._v("外部表的使用场景")])]),t._v(" "),a("ul",[a("li",[t._v("原始日志文件或同时被多个部门同时操作的数据集，需要使用外部表")]),t._v(" "),a("li",[t._v("如果不小心将meta data删除了，HDFS上的数据还在，可以恢复，增加了数据的安全性")])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("注意:使用insert插入数据时会产生临时表，重新连接后会表会小时，因此大批量插入数据时不建议用insert`\n`tips1:在hdfs的hive路径下以.db结尾的其实都是实际的数据库`\n`tips2:默认的default数据库就在hive的家目录\n")])])]),a("p",[t._v("``")]),t._v(" "),a("h3",{attrs:{id:"_3-分区表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-分区表"}},[t._v("#")]),t._v(" 3. 分区表")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("注意:分区表通常分为静态分区表和动态分区表，前者需要导入数据时静态指定分区，后者可以直接根据导入数据进行分区。分区的好处是可以让数据按照区域进行分类，避免了查询时的全表扫描。\n# 创建外部分区表，指定静态分区为dt\nCREATE EXTERNAL TABLE if not exists aiops.tmpOnline(ip string,\nstatus string,\n....\n)\nPARTITIONED BY (\n  dt string);\n\n# 导入数据到静态分区表中(需要注意的是数据中没有dt字段)\nload data local inpath '/home/hdfs/tmpOnline' overwrite into table aiops.tmpOnline PARTITION (dt='99991231');\n\n# 动态分区表的使用(动态分区和静态分区表的创建时没有区别的)\n# 注意:hive默认没有开启动态分区，需要进行参数修改\n# 使用动态分区的记录中，必须在指定位置包含动态分区的字段才能被动态分区表识别\nhive>set hive.exec.dynamic.partition.mode=nonstrict;\nhive>\ninsert\n  overwrite\ntable aiops.tmpOnline\npartition(dt)\nselect\nip,appname,....,from_unixtime(unix_timestamp(),'yyyyMMdd') as dt from table;\n  \n# 手动添加分区\nalter table tablename add partition (dt='20181009');\n# 删除分区，数据也会删除(所以一般会使用外部分区表？)\n## 注意:如果数据有变动，是无法将数据load到同一个时间分区的记录的\nalter table tablename drop partition (dt='20181009');\n# 查询分区表没有加分区过滤，会禁止提交这个任务(strict方式每次查询必须制定分区)\nset hive.mapred.mode = strict|nostrict;\n注意:在外部分区表中，如果将表删除了，重建表后只需要将分区加载进来即可恢复历史相关分区的数据。\n")])])]),a("p",[a("strong",[t._v("多重分区的使用")])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("# 创建多重分区表\ncreate table log_m (\n    id  int,\n    name string,\n    age int\n)\npartitioned by (year string,month string,day string)\nrow format delimited\nfields terminated by '|'\ncollection items terminated by ','\nmap keys terminated by ':'\nlines terminated by '\\n';\n\n# 插入数据\ninsert into table log_m partition  (year='2018',month='10',day='10') values(1,'biaoge',24);\ninsert into table log_m partition  (year='2018',month='10',day='09') values(2,'bgbiao',25);\nhive> show partitions log_m;\nOK\nyear=2018/month=10/day=09\nyear=2018/month=10/day=10\nTime taken: 0.055 seconds, Fetched: 2 row(s)\nhive>\n\n# 多重动态分区\n# 好像动态分区表不能直接load data\nhive> insert into table log_m partition(year,month,day) values(3,'xuxuebiao',28,'2016','09','10');\nhive> show partitions log_m;\nOK\nyear=2016/month=09/day=10\nyear=2018/month=10/day=09\nyear=2018/month=10/day=10\n\n# 查询分区数据\nhive> select * from log_m where year = '2018';\nOK\n2 bgbiao  25  2018  10  09\n1 biaoge  24  2018  10  10\n2 bgbiao  25  2018  10  10\n")])])]),a("h2",{attrs:{id:"二、hive的复杂数据类型的使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二、hive的复杂数据类型的使用"}},[t._v("#")]),t._v(" "),a("strong",[t._v("二、Hive的复杂数据类型的使用")])]),t._v(" "),a("p",[t._v("**\n**")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("注意:Hive之所以能在大数据领域比较受欢迎，很大一部分原因在于相比其他SQL类存储系统支持更加复杂的数据类型\n")])])]),a("ul",[a("li",[a("strong",[t._v("map")]),t._v(": (key1, value1, key2, value2, ...) 一些列的k/v对 map<int,string...>")]),t._v(" "),a("li",[a("strong",[t._v("struct")]),t._v(": (var1,var2,var3...) 不同类型的值的组合 struct"),a("a",{attrs:{href:"abc:string,def:int..."}},[t._v("abc:string,def:int...")])]),t._v(" "),a("li",[a("strong",[t._v("array")]),t._v(": (var1,var2,var3...) 一种类型的值的组合 array<string...>")]),t._v(" "),a("li",[a("strong",[t._v("uniontype")]),t._v(": (string,map<>,struct<>,array<>)")])]),t._v(" "),a("p",[a("code",[t._v("注意:在创建hive表时可根据需要导入的数据进行类型识别并创建适合的数据类型")]),t._v("\nhive数据类型数据识别标识:")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"left"}},[t._v("字段分割标识")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("含义")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("FIELDS TERMINATED BY")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("表示字段与字段之间的分隔符")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("COLLECTION ITEMS TERMINATED BY")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("表示一个字段中各个item之间的分隔符[可用于array和struct类型]")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("MAP KEYS TERMINATED BY")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("表示map类型中的key/value的分隔符[可用于map类型]")])])])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('# 创建表\ncreate table union_testnew(\n  foo uniontype<int, double, string, array<string>, map<string, string>>\n)\nrow format delimited\ncollection items terminated by \',\'\nmap keys terminated by \':\'\nlines terminated by \'\\n\'\nstored as textfile;\n\n# 数据准备\n[root@master wadeyu]# vim union_test.log\n  1 0,1\n  2 1,3.0\n  3 2,world\n  4 3,wade:tom:polly\n  5 4,k1^Dv1:k2^Dv2\n\n# 导入数据\nhive (badou)> load data local inpath \'./union_test.log\' overwrite into table union_testnew;\n\n# 查询数据\nhive (badou)> select * from union_testnew;\nOK\nunion_testnew.foo\n{0:1}\n{1:3.0}\n{2:"world"}\n{3:["wade","tom","polly"]}\n{4:{"k1":"v1","k2":"v2"}}\nTime taken: 0.225 seconds, Fetched: 5 row(s)\n')])])]),a("h3",{attrs:{id:"_1-array类型的使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-array类型的使用"}},[t._v("#")]),t._v(" 1. array类型的使用")]),t._v(" "),a("h4",{attrs:{id:"_1-1-array类型的基本使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-array类型的基本使用"}},[t._v("#")]),t._v(" 1.1 array类型的基本使用")]),t._v(" "),a("p",[a("code",[t._v("类型结构:")]),t._v(" array"),a("struct",[t._v(" 例如:array"),a("string",[t._v(",array"),a("int",[a("code",[t._v("数据表示:")]),t._v(" 例如:[string1,string2],[int1,int2]")])],1)],1)],1),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('# 原始文件\nbmpjob P2 bgops 服务研发组 10.0.0.212,10.0.0.225,10.0.0.243,10.0.55.31\n\n# 创建数据库\nhive> create table appinfo\n    > (\n    > appname string,\n    > level string,\n    > leader string,\n    > dep string,\n    > ips  array<string>)\n    > ROW FORMAT DELIMITED\n    > FIELDS TERMINATED BY \' \'\n    > COLLECTION ITEMS TERMINATED BY \',\';\n\n# 加载数据到hive\nhive> load data inpath \'hdfs://hdfs-name/aiops/wander/appinfo.txt\' overwrite into table appinfo;\nLoading data to table test.appinfo\nTable test.appinfo stats: [numFiles=1, numRows=0, totalSize=32568, rawDataSize=0]\nOK\n\n# 查询相关数据\nhive> select * from appinfo limit 1;\nOK\nbmpjob P2 bgops 服务研发组 ["10.0.0.212","10.0.0.225","10.0.0.243","10.0.55.31"]\n\nhive> select appname,leader,ips[0] from appinfo limit 1;\nOK\nbmpjob bgops 10.0.0.212\n')])])]),a("h4",{attrs:{id:"_1-2-array类型数据转换处理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-array类型数据转换处理"}},[t._v("#")]),t._v(" "),a("strong",[t._v("1.2 array"),a("struct",[t._v("类型数据转换处理")])],1)]),t._v(" "),a("blockquote",[a("p",[t._v("背景:\n使用array结构时，一个字段中通常会有多个值，这个时候通常情况下是需要对某个值进行过滤的，一般情况下会使用"),a("code",[t._v("lateral view结合UDTF(User-Defined Table-Generating Functions)进行过滤")]),t._v("。而UDTF为了解决一行输出多行的需求，典型的就是explode()函数。")])]),t._v(" "),a("p",[a("strong",[t._v("lateral view语法结构")])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("lateralView: LATERAL VIEW udtf(expression) tableAlias AS columnAlias (',' columnAlias)\n")])])]),a("p",[a("strong",[t._v("array"),a("struct",[t._v("转字符串")])],1)]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("# 借用split函数将array<string>结构内容转换为以\",\"分割的字符串\nselect split(array<string>,',') from tablename\n")])])]),a("p",[a("strong",[t._v("hive使用explode()函数进行")]),t._v("**"),a("code",[t._v("行转列")]),t._v("**\n"),a("code",[t._v("语法:lateral view explode(col3) col3 as name")])]),t._v(" "),a("ul",[a("li",[t._v("explode(ARRAY): 列表中的每个元素生成一行")]),t._v(" "),a("li",[t._v("explode(MAP): map中每个key-value对，生成一行，key为一列，value为一列")])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("hive> select ip,appname from appinfo LATERAL VIEW explode(ips) tmpappinfo  AS ip limit 2;\n10.0.0.212 bmpjob\n10.0.0.225 bmpjob\n")])])]),a("p",[a("strong",[t._v("hive使用concat_ws()函数进行"),a("code",[t._v("列转行")])])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("# 借用concat_ws()和collect_set()函数进行相同列的重复数据转换\n# collect_set()函数可以将相关列合并成array<>类型；concat_ws()函数会将array<>类型根据指定的分隔符进行合并\n## 示例数据\nhive> select * from tmp_jiangzl_test;\ntmp_jiangzl_test.col1   tmp_jiangzl_test.col2   tmp_jiangzl_test.col3\na       b       1\na       b       2\na       b       3\nc       d       4\nc       d       5\nc       d       6\n## 对于以上数据，我们可以将col3列根据列col1和col2进行合并\nhive> select col1,col2,concat_ws(',',collect_set(col3)) from tmp_jiangzl_test group by col1,col2;\ncol1    col2    _c2\na       b       1,2,3\nc       d       4,5,6\n")])])]),a("h3",{attrs:{id:"_2-struct-类型的使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-struct-类型的使用"}},[t._v("#")]),t._v(" 2. struct<>类型的使用")]),t._v(" "),a("p",[a("code",[t._v("数据定义:")]),t._v(" struct<name:STRING, age:INT>\n"),a("code",[t._v("数据表示:")]),t._v(" biaoge:18")]),t._v(" "),a("p",[t._v("示例:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("# 元数据格式\n1,zhou:30\n2,yan:30\n3,chen:20\n# 相关数据库结构\nhive> create table test-struct(id INT, info struct<name:STRING, age:INT>)\n    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\n    > COLLECTION ITEMS TERMINATED BY ':';\n# 加载数据\nhive> LOAD DATA LOCAL INPATH '/home/work/data/test5.txt' INTO TABLE test-struct;\n# 查询相关数据\nhive> select info.age from test-struct;\nTotal MapReduce jobs = 1\n......\nTotal MapReduce CPU Time Spent: 490 msec\nOK\n30\n30\n")])])]),a("h3",{attrs:{id:"_3-map-类型的使用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-map-类型的使用"}},[t._v("#")]),t._v(" 3. map<>类型的使用")]),t._v(" "),a("p",[a("code",[t._v("数据定义:")]),t._v(" map<string,int>\n"),a("code",[t._v("数据表示:")]),t._v(" key:value,key:value...\n示例：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("# 原始数据格式\n1       job:80,team:60,person:70\n2       job:60,team:80\n3       job:90,team:70,person:100\n\n# map结构的表结构创建\nhive> create table employee(id string, perf map<string, int>)\n    > ROW FORMAT DELIMITED\n    > FIELDS TERMINATED BY '\\t'\n    > COLLECTION ITEMS TERMINATED BY ','\n    > MAP KEYS TERMINATED BY ':';\n\n# 数据导入\nhive>  LOAD DATA LOCAL INPATH '/home/work/data/test7.txt' INTO TABLE employee;\n\n# 数据查询\nhive> select perf['person'] from employee;\nTotal MapReduce jobs = 1\n......\nTotal MapReduce CPU Time Spent: 460 msec\nOK\n70\nNULL\n\n# 使用explode()函数查询\nhive> select explode(perf) as (p_name,p_score) from employee limit 4;\nOK\njob 80\nteam 60\nperson 70\n\n# 使用explode()和lateral view结合查询\nhive> select id,p_name,p_score from employee lateral view explode(perf) perf as p_name,p_score limit 3;\nOK\n1 job 80\n1 team 60\n1 person 70\n\n# 使用size()函数查看map结构中的键值对个数[也可查看array中的元素个数]\nhive> select size(perf) from employee\n3\n2\n3\n")])])]),a("h2",{attrs:{id:"三、hive的常用函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#三、hive的常用函数"}},[t._v("#")]),t._v(" 三、Hive的常用函数")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("注意:使用show functions可以查看hive支持的相关函数\n")])])]),a("h3",{attrs:{id:"_1-hive常用函数列表"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_1-hive常用函数列表"}},[t._v("#")]),t._v(" 1. hive常用函数列表")]),t._v(" "),a("p",[a("strong",[t._v("标准函数使用:")])]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"left"}},[t._v("函数名")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("作用描述")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("round()/floor()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("可以将double类型转换为bigint类型")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("abs()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("返回数值的绝对值")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("ucase()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("将字符串转换成全是大写字母")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("reverse()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("将字符串进行翻转")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("concat()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("将输入的多个字符串当做一个字符串输出concat('"),a("img",{attrs:{src:"https://mmbiz.qpic.cn/mmbiz_svg/I1YzhXxW8YC0zJIYJ3ibAGXSTIjKchicib82NNulxl8nmlUsqQzTxSwTct0Gn93PBZsD0ibcrasuUv1tdOF8iaE92vOy8l9SGyfzX/640?wx_fmt=other&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1",alt:"图片"}}),t._v("171")])])])]),t._v(" "),a("p",[a("strong",[t._v("聚合函数使用:")])]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"left"}},[t._v("函数名")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("作用描述")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("sum()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("返回所有输入求和后的值")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("avg()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("计算所有输入值的平均值")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("min()/max()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("计算输入值的最大和最小值")])])])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("注意:聚合方法通常需要和group by语句组合使用\n")])])]),a("p",[a("strong",[t._v("表生成函数:")]),t._v("\n表生成函数接收零个或者多个输入，然后产生多列或多行输出.")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"left"}},[t._v("函数名")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("作用描述")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("array()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("将函数内容转换成一个array<>类型")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("split(array,split)")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("将array<>类型按照split分割符进行分割成字符串(转义时使用\\进行转义)")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("explode()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("array数据类型作为输入，对数组中数据进行迭代，返回多行结果")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("collect_set()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("将某字段的值进行去重汇总，产生Array类型字段")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("collect_list()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("同collect_set()，但是不会对字段进行去重")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("concat_ws(split,struct)")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("将struct类型的字段按照split进行分割成字符串(struct仅支持string和array<>类型)")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("cast(column as type)")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("转换数据类型(column列转换为type类型)")])])])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('注意:当split被包含在""之中的时候需要使用四个\\进行转义[比如在hive -e ""中执行split函数]\n## array()函数可以将一列输入转换成一个数组输出\nhive> select array(1,2,3) from xuxuebiao;\nOK\n[1,2,3]\n[1,2,3]\n\n## explode()函数以array数据类型作为输入，对数组中数据进行迭代，返回多行结果\nhive> select explode(array(1,2,3)) from xuxuebiao;\nOK\n1\n2\n3\n## 使用explode()函数查看array中的某个元素\nhive> select * from appinfo LATERAL VIEW explode(ips) tmpappinfo  AS realid         where realid =\'10.0.0.125\' ;\n\n## collect_set函数\n### 该函数的作用是将某字段的值进行去重汇总，产生Array类型字段\nhive> select * from test;\nOK\n1       A\n1       C\n1       B\nhive>  select id,collect_set(name) from test group by id;\nOK\n1       ["A","C","B"]\n')])])]),a("h3",{attrs:{id:"_2-常用的条件判断以及数据清洗函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-常用的条件判断以及数据清洗函数"}},[t._v("#")]),t._v(" 2.常用的条件判断以及数据清洗函数")]),t._v(" "),a("p",[t._v("在使用hive处理数据过程中，通常我们需要对相关数据进行清洗转换，此时我们可能会使用一些条件判断以及默认值处理函数。")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"left"}},[t._v("函数名")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("作用描述")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("IF( Test Condition, True Value, False Value )")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("判断条件，满足即为True值，不满足即为False值")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("CASE Statement")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("多条件判断")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("parse_url()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("通常用于清洗url相关函数，提供了常用的url解析功能")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("parse_url_tuple()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("同上")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("regexp_replace()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("正则表达式替换")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("regexp_extract()")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("正则表达式解析")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("COALESCE(column,'')")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("hive中的空值转换(hive中的空值为NULL，而存储到hdfs中会以\\N来存储)")])])])]),t._v(" "),a("p",[t._v("示例:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("# if条件判断常用于不同规格数据的清洗操作\nhive> select ip,if(assign != '分配状态未知',0,assign) as fenpei  from asset ;\nOK\n10.0.0.1 分配状态未知\n\n# case多条件判断\nhive> select ip,\n    case\n        when assign = '已分配' then 1\n        when assign = '未分配' then 2\n        else 0\n    end\n    as fenpei\nfrom asset\n\nhive (ods)> select name,salary,\n          > case when salary < 800 then 'low'\n          > when salary >= 800 and salary <=5000 then 'middle'\n          > when salary >5000 and salary <10000 then 'high'\n          > else 'very high'\n          > end as bracket\n          > from emp1;\n\n\n# parser_url()函数\nhive> select parse_url('https://www.baidu.com/s?cl=3&tn=baidutop10&fr=top1000&wd=%E8%BF%AA%E5%A3%AB%E5%B0%BC%E6%94%B6%E8%B4%AD%E7%A6%8F%E5%85%8B%E6%96%AF&rsv_idx=2','HOST') ;\nwww.baidu.com\n\n# 正则表达式\nhive> select regexp_replace('foobar', 'oo|ar', '');\nselect regexp_replace('foobar', 'oo|ar', '-');\n## 输出第一个回溯引用(.*?)匹配到的内容即the\nselect regexp_extract('foothebar', 'foo(.*?)(bar)', 1);\n## 输出第而个回溯引用(bar)匹配到的内容即bar\nselect regexp_extract('foothebar', 'foo(.*?)(bar)', 2);\n## 输出全部内容\nselect regexp_extract('foothebar', 'foo(.*?)(bar)', 0);\n\n\n# 清洗组合\nselect if(4>5,5000,1000),coalesce(null,1,3,5),coalesce(null,null,null,null), case 3 when 1 then 'lala' when 2 then 'chye' else 'abc' end;\n")])])]),a("h3",{attrs:{id:"_3-hive高级函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_3-hive高级函数"}},[t._v("#")]),t._v(" 3. hive高级函数")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("row_number() over()\n")])])]),a("h2",{attrs:{id:"三、hive常用的环境变量"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#三、hive常用的环境变量"}},[t._v("#")]),t._v(" 三、hive常用的环境变量")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",{staticStyle:{"text-align":"left"}},[t._v("环境变量")]),t._v(" "),a("th",{staticStyle:{"text-align":"left"}},[t._v("含义")])])]),t._v(" "),a("tbody",[a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("set hive.cli.print.header=true")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("设置查询时显示表头")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("set hive.exec.dynamic.partition=true")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("开启动态分区")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("set hive.exec.dynamic.partition.mode=nonstrict")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("设置动态分区模式为非严格")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("set hive.exec.max.dynamic.partitions.pernode = 1000")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("设置每个执行MR的节点上最大分区数")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("set hive.exec.max.dynamic.partitions=1000")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("设置所有MR节点上最大总分区数")])]),t._v(" "),a("tr",[a("td",{staticStyle:{"text-align":"left"}},[t._v("SET SERDEPROPERTIES('serialization.null.format' = '\\N')")]),t._v(" "),a("td",{staticStyle:{"text-align":"left"}},[t._v("设置hive空值存储方式为'\\N'(此时存储在HDFS中时'\\N',查询显示为NULL)")])])])]),t._v(" "),a("p",[t._v("​")])])}),[],!1,null,null,null);e.default=l.exports}}]);