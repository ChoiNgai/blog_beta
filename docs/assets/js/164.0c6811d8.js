(window.webpackJsonp=window.webpackJsonp||[]).push([[164],{532:function(_,t,v){"use strict";v.r(t);var r=v(30),s=Object(r.a)({},(function(){var _=this,t=_.$createElement,v=_._self._c||t;return v("ContentSlotsDistributor",{attrs:{"slot-key":_.$parent.slotKey}},[v("hr"),_._v(" "),v("h1",{attrs:{id:"flink-面试题"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#flink-面试题"}},[_._v("#")]),_._v(" Flink 面试题")]),_._v(" "),v("h2",{attrs:{id:"_1、应用架构"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_1、应用架构"}},[_._v("#")]),_._v(" 1、应用架构")]),_._v(" "),v("p",[v("strong",[_._v("问题")]),_._v("：公司怎么提交的实时任务，有多少 Job Manager？")]),_._v(" "),v("p",[v("strong",[_._v("解答")]),_._v("：")]),_._v(" "),v("p",[_._v("        1. 我们使用 "),v("code",[_._v("yarn session")]),_._v(" 模式提交任务。每次提交都会创建一个新的 Flink 集群，为每一个 job 提供一个 "),v("code",[_._v("yarn-session")]),_._v("，任务之间互相独立，互不影响， 方便管理。任务执行完成之后创建的集群也会消失。线上命令脚本如下：")]),_._v(" "),v("div",{staticClass:"language-bash extra-class"},[v("pre",{pre:!0,attrs:{class:"language-bash"}},[v("code",[_._v("bin/yarn-session.sh -n "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("7")]),_._v(" -s "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("8")]),_._v(" -jm "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("3072")]),_._v(" -tm "),v("span",{pre:!0,attrs:{class:"token number"}},[_._v("32768")]),_._v(" -qu root.*.* -nm *-* -d\n")])])]),v("p",[_._v("        其中申请 7 个 taskManager，每个 8 核，每个 taskmanager 有 32768M 内存。")]),_._v(" "),v("p",[_._v("        2. 集群默认只有一个 Job Manager。但为了防止单点故障，我们配置了高可用。 我们公司一般配置一个主 Job Manager，两个备用 Job Manager，然后结合 ZooKeeper 的使用，来达到高可用。")]),_._v(" "),v("h2",{attrs:{id:"_2、压测和监控"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_2、压测和监控"}},[_._v("#")]),_._v(" 2、压测和监控")]),_._v(" "),v("p",[v("strong",[_._v("问题")]),_._v("：怎么做压力测试和监控？")]),_._v(" "),v("p",[v("strong",[_._v("解答")]),_._v("：我们一般碰到的压力来自以下几个方面：")]),_._v(" "),v("p",[_._v("        一，产生数据流的速度如果过快，而下游的算子消费不过来的话，会产生"),v("strong",[_._v("背压")]),_._v("。 背压的监控可以使用 "),v("strong",[_._v("Flink Web UI")]),_._v("(localhost:8081) 来"),v("strong",[_._v("可视化监控")]),_._v("，一旦报警就能知道。一般情况下背压问题的产生可能是由于 "),v("strong",[_._v("sink")]),_._v(" 这个 操作符没有优化好，做一下 优化就可以了。比如如果是写入 ElasticSearch， 那么可以改成"),v("strong",[_._v("批量写入")]),_._v("，可以调 大 ElasticSearch "),v("strong",[_._v("队列的大小")]),_._v("等等策略。")]),_._v(" "),v("p",[_._v("        二，设置 watermark 的"),v("strong",[_._v("最大延迟时间")]),_._v("这个参数，如果设置的过大，可能会造成"),v("strong",[_._v("内存的压力")]),_._v("。可以设置最大延迟时间小一些，然后把迟到元素发送到"),v("strong",[_._v("侧输出流")]),_._v("中去。 晚一点更新结果。或者使用类似于 "),v("strong",[_._v("RocksDB")]),_._v(" 这样的状态后端， RocksDB 会开辟堆外存储空间，但 IO 速度会变慢，需要权衡。")]),_._v(" "),v("p",[_._v("        三，还有就是"),v("strong",[_._v("滑动窗口的长度")]),_._v("如果过长，而滑动距离很短的话，Flink 的性能会下降的很厉害。我们主要通过"),v("strong",[_._v("时间分片")]),_._v("的方法，将每个元素只存入一个“重叠窗 口”，这样就可以减少窗口处理中状态的写入。（详情链接："),v("a",{attrs:{href:"https://www.infoq.cn/article/sIhs_qY6HCpMQNblTI9M",target:"_blank",rel:"noopener noreferrer"}},[_._v("Flink 滑动窗口优化"),v("OutboundLink")],1),_._v("）")]),_._v(" "),v("p",[_._v("        四，"),v("strong",[_._v("状态后端")]),_._v("使用 RocksDB，还没有碰到被撑爆的问题")]),_._v(" "),v("h2",{attrs:{id:"_3、为什么用-flink"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_3、为什么用-flink"}},[_._v("#")]),_._v(" 3、为什么用 Flink")]),_._v(" "),v("p",[v("strong",[_._v("问题")]),_._v("：为什么使用 Flink 替代 Spark？")]),_._v(" "),v("p",[v("strong",[_._v("解答")]),_._v("：主要考虑的是 flink 的"),v("strong",[_._v("低延迟")]),_._v("、"),v("strong",[_._v("高吞吐量")]),_._v("和对"),v("strong",[_._v("流式数据")]),_._v("应用场景更好的支持；另外，flink 可以很好地处理"),v("strong",[_._v("乱序")]),_._v("数据，而且可以保证 "),v("strong",[_._v("exactly-once")]),_._v(" 的状态一致性。")]),_._v(" "),v("h2",{attrs:{id:"_4、checkpoint-的理解"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_4、checkpoint-的理解"}},[_._v("#")]),_._v(" 4、checkpoint 的理解")]),_._v(" "),v("p",[v("strong",[_._v("问题")]),_._v("：如何理解Flink的"),v("strong",[_._v("checkpoint")])]),_._v(" "),v("p",[v("strong",[_._v("解答")]),_._v("：Checkpoint是Flink实现"),v("strong",[_._v("容错机制")]),_._v("最核心的功能，它能够根据配置周期性地基于Stream中各个Operator/task的状态来生成"),v("strong",[_._v("快照")]),_._v("，从而将这些状态数据"),v("strong",[_._v("定期持久化存储")]),_._v("下来，当Flink程序一旦意外崩溃时，重新运行程序时可以有选择地从这些快照进行恢复，从而修正因为故障带来的程序数据异常。他可以存在内存，文件系统，或者 RocksDB。")]),_._v(" "),v("h2",{attrs:{id:"_5、exactly-once-的保证"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_5、exactly-once-的保证"}},[_._v("#")]),_._v(" 5、exactly-once 的保证")]),_._v(" "),v("p",[v("strong",[_._v("问题")]),_._v("：如果下级存储不支持事务，Flink 怎么保证 exactly-once？")]),_._v(" "),v("p",[v("strong",[_._v("解答")]),_._v("：端到端的 exactly-once 对 sink 要求比较高，具体实现主要有"),v("strong",[_._v("幂等写入")]),_._v("和 "),v("strong",[_._v("事务性")]),_._v("写入两种方式。幂等写入的场景依赖于业务逻辑，更常见的是用事务性写入。 而事务性写入又有"),v("code",[_._v("预写日志（WAL）")]),_._v("和"),v("code",[_._v("两阶段提交（2PC）")]),_._v("两种方式。")]),_._v(" "),v("p",[_._v("        如果外部系统不支持事务，那么可以用"),v("strong",[_._v("预写日志")]),_._v("的方式，把结果数据先当成状态保存，然后在收到 "),v("strong",[_._v("checkpoint")]),_._v(" 完成的通知时，一次性写入 sink 系统。")]),_._v(" "),v("h2",{attrs:{id:"_6、状态机制"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_6、状态机制"}},[_._v("#")]),_._v(" 6、状态机制")]),_._v(" "),v("p",[v("strong",[_._v("问题")]),_._v("：说一下 Flink 状态机制？")]),_._v(" "),v("p",[v("strong",[_._v("解答")]),_._v("：Flink 内置的很多算子，包括源 source，数据存储 sink 都是有状态的。在 Flink 中，"),v("strong",[_._v("状态始终与特定算子相关联")]),_._v("。Flink 会以 "),v("strong",[_._v("checkpoint")]),_._v(" 的形式对各个任务的 状态进行快照，用于保证故障恢复时的"),v("strong",[_._v("状态一致")]),_._v("性。Flink 通过状态后端来管理状态 和 checkpoint 的存储，状态后端也可以有不同的配置选择。")]),_._v(" "),v("h2",{attrs:{id:"_7、海量-key-去重"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_7、海量-key-去重"}},[_._v("#")]),_._v(" 7、海量 key 去重")]),_._v(" "),v("p",[v("strong",[_._v("问题")]),_._v("：怎么去重？考虑一个实时场景：双十一场景，滑动窗口长度为 1 小时， 滑动距离为 10 秒钟，亿级用户，怎样计算 UV？")]),_._v(" "),v("p",[v("strong",[_._v("解答")]),_._v("：使用类似于 scala 的 set 数据结构或者 redis 的 set 显然是不行的， 因为可能有上亿个 Key，内存放不下。所以可以考虑使用"),v("strong",[_._v("布隆过滤器")]),_._v("（Bloom Filter） 来去重。")]),_._v(" "),v("h2",{attrs:{id:"_8、checkpoint-与-spark-比较"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_8、checkpoint-与-spark-比较"}},[_._v("#")]),_._v(" 8、checkpoint 与 spark 比较")]),_._v(" "),v("p",[_._v("        问题：Flink 的 "),v("strong",[_._v("checkpoint")]),_._v(" 机制对比 spark 有什么不同和优势？")]),_._v(" "),v("p",[v("strong",[_._v("解答：")]),_._v(" spark streaming 的 checkpoint 仅仅是针对 driver 的故障恢复做了"),v("strong",[_._v("数据和元数据的checkpoint")]),_._v("。而 flink 的 checkpoint 机制要复杂了很多，它采用的是轻量级的分布式快照，实现了"),v("strong",[_._v("每个算子的快照，及流动中的数据的快照")]),_._v("。")]),_._v(" "),v("h2",{attrs:{id:"_9、watermark-机制"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_9、watermark-机制"}},[_._v("#")]),_._v(" 9、watermark 机制")]),_._v(" "),v("p",[v("strong",[_._v("问题")]),_._v("：请详细解释一下 Flink 的 Watermark 机制。")]),_._v(" "),v("p",[v("strong",[_._v("解答")]),_._v("：在使用 EventTime 处理 Stream 数据的时候会遇到数据乱序的问题，流处理从 Event（事 件）产生，流经 Source，再到 Operator，这中间需要一定的时间。虽然大部分情况下，传输到 Operator 的数据都是按照"),v("strong",[_._v("事件产生的时间")]),_._v("顺序来的，但是也不排除由于"),v("strong",[_._v("网络延迟")]),_._v("等原因而导致乱序的产生，特别是使用 Kafka 的时候，多个分区之间的数据无法保证有序。因此， "),v("font",{attrs:{color:"RoyalBlue"}},[v("strong",[_._v("在进行 Window 计算的时候，不能无限期地等下去，必须要有个机制来保证在特定的时间后， 必须触发 Window 进行计算")])]),_._v("，这个特别的机制就是 "),v("strong",[_._v("Watermark（水位线）")]),_._v("。Watermark是用于"),v("strong",[_._v("处理乱序事件")]),_._v("的。")],1),_._v(" "),v("p",[_._v("        在 Flink 的窗口处理过程中，如果确定全部数据到达，就可以对 Window 的所有数据做窗口计算操作（如汇总、分组等），如果数据没有全部到达，则"),v("strong",[_._v("继续等待该窗口中的数据全部到达才开始处理")]),_._v("。这种情况下就需要用到"),v("strong",[_._v("水位线(WaterMarks")]),_._v(")机制，它能够"),v("font",{attrs:{color:"RoyalBlue"}},[v("strong",[_._v("衡量数据处理进度（表达数据到达的完整性）")])]),_._v("，保证事件数据（全部）到达 Flink 系统，或者在乱序及延迟到达时，也能够像预期一样计算出正确并且连续的结果。")],1),_._v(" "),v("h2",{attrs:{id:"_10、exactly-once-如何实现"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_10、exactly-once-如何实现"}},[_._v("#")]),_._v(" 10、exactly-once 如何实现")]),_._v(" "),v("p",[v("strong",[_._v("问题")]),_._v("：Flink 中 "),v("code",[_._v("exactly-once")]),_._v(" 语义是如何实现的，状态是如何存储的？")]),_._v(" "),v("p",[_._v("        解答：Flink 依靠 "),v("strong",[_._v("checkpoint")]),_._v(" 机制来实现 "),v("strong",[_._v("exactly-once")]),_._v(" 语义，如果要实现端到端 的 exactly-once，还需要外部 source 和 sink 满足一定的条件。状态的存储通过状态 后端来管理，Flink 中可以配置不同的状态后端。")]),_._v(" "),v("h2",{attrs:{id:"_11、cep"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_11、cep"}},[_._v("#")]),_._v(" 11、CEP")]),_._v(" "),v("p",[v("strong",[_._v("问题")]),_._v("：Flink CEP 编程中当状态没有到达的时候会将数据保存在哪里？")]),_._v(" "),v("p",[v("strong",[_._v("解答")]),_._v("：在流式处理中，CEP 当然是要支持 "),v("strong",[_._v("EventTime")]),_._v(" 的，那么相对应的也要支持数据的迟到现象，也就是 watermark的处理逻辑。CEP对未匹配成功的事件序 列的处理，和迟到数据是类似的。在 Flink CEP 的处理逻辑中，"),v("strong",[_._v("状态没有满足的和迟到的数据，都会存储在一个 Map 数据结构中")]),_._v("，也就是说，如果我们限定判断事件 序列的时长为5 分钟，那么内存中就会存储 5 分钟的数据，这在我看来，也是对内存的极大损伤之一。")]),_._v(" "),v("h2",{attrs:{id:"_12、三种时间语义"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_12、三种时间语义"}},[_._v("#")]),_._v(" 12、三种时间语义")]),_._v(" "),v("p",[v("strong",[_._v("问题")]),_._v("：Flink 三种时间语义是什么，分别说出应用场景？")]),_._v(" "),v("p",[v("strong",[_._v("解答")]),_._v("：")]),_._v(" "),v("ul",[v("li",[v("p",[v("strong",[_._v("Event Time")]),_._v("：这是实际应用最常见的时间语义，指的是事件创建的时间，"),v("strong",[_._v("往往跟watermark结合使用")])])]),_._v(" "),v("li",[v("p",[v("strong",[_._v("Processing Time")]),_._v("：指每一个执行基于时间操作的算子的本地系统时间，与机器相关。适用场景：没有事件时间的情况下，或者"),v("strong",[_._v("对实时性要求超高")]),_._v("的情况")])]),_._v(" "),v("li",[v("p",[v("strong",[_._v("Ingestion Time")]),_._v("：指数据进入Flink的时间。适用场景："),v("strong",[_._v("存在多个 Source Operator")]),_._v(" 的情况下，每个 Source Operator 可以使用自己本地系统时钟指派 Ingestion Time。后续基于时间相关的各种操作， 都会使用数据记录中的 Ingestion Time")])])]),_._v(" "),v("h2",{attrs:{id:"_13、数据高峰的处理"}},[v("a",{staticClass:"header-anchor",attrs:{href:"#_13、数据高峰的处理"}},[_._v("#")]),_._v(" 13、数据高峰的处理")]),_._v(" "),v("p",[v("strong",[_._v("问题")]),_._v("：Flink 程序在面对数据高峰期时如何处理？")]),_._v(" "),v("p",[v("strong",[_._v("解答")]),_._v("：使用大容量的 Kafka 把数据先放到消息队列里面作为数据源，再使用 Flink 进行消费，不过这样会影响到一点实时性。\n        ")])])}),[],!1,null,null,null);t.default=s.exports}}]);