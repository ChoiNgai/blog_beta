(window.webpackJsonp=window.webpackJsonp||[]).push([[12],{405:function(a,t,s){"use strict";s.r(t);var n=s(30),e=Object(n.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("h1",{attrs:{id:"hdfs常用的40个命令"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#hdfs常用的40个命令"}},[a._v("#")]),a._v(" HDFS常用的40个命令")]),a._v(" "),s("h2",{attrs:{id:"前言"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#前言"}},[a._v("#")]),a._v(" 前言")]),a._v(" "),s("p",[a._v("        众所周知，Hadoop 提供了命令行接口，对HDFS中的文件进行管理操作，如"),s("font",{attrs:{color:"\tTomato"}},[s("strong",[a._v("读取文件")]),a._v("、"),s("strong",[a._v("新建目录")]),a._v("、"),s("strong",[a._v("移动文件")]),a._v("、"),s("strong",[a._v("复制文件")]),a._v("、"),s("strong",[a._v("删除目录")]),a._v("、"),s("strong",[a._v("上传文件")]),a._v("、"),s("strong",[a._v("下载文件")]),a._v("、"),s("strong",[a._v("列出目录")])]),a._v("等。本期文章，菌哥打算为大家详细介绍 Hadoop 的命令行接口！希望大家看完之后，能够有所收获\n|ू･ω･` )\n        ")],1),a._v(" "),s("p",[a._v("        HDFS命令行的格式如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("Hadoop fs -cmd "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("args"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("\n")])])]),s("p",[a._v("        其中，cmd是要执行的具体命令；"),s("args",[a._v("是要执行命令的参数，但不限于一个参数。")])],1),a._v(" "),s("p",[a._v("        要查看命令行接口的帮助信息，只需在命令行中输入如下命令：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs\n")])])]),s("p",[a._v("        即不添加任务具体的执行命令，Hadoop 就会列出命令行接口的帮助信息，如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs")]),a._v("\nUsage: hadoop fs "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("generic options"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-appendToFile "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("localsrc"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v(". "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("dst"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-cat "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-ignoreCrc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-checksum "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-chgrp "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-R"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" GROUP "),s("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("PATH")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-chmod "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-R"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("MODE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v(",MODE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v(". "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" OCTALMODE"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("PATH")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-chown "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-R"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("OWNER"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v(":"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("GROUP"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token environment constant"}},[a._v("PATH")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-copyFromLocal "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-l"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("localsrc"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v(". "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("dst"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-copyToLocal "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-ignoreCrc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-crc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v(". "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("localdst"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-count "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-v"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-cp "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-p "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" -p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("topax"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v(". "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("dst"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-createSnapshot "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("snapshotDir"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("snapshotName"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-deleteSnapshot "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("snapshotDir"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("snapshotName"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-df "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-du "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-s"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-expunge"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-find "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v(". "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("expression"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-get "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-ignoreCrc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-crc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v(". "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("localdst"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-getfacl "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-R"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-getfattr "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-R"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("-n name "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" -d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-e en"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-getmerge "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-nl"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("localdst"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-help "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("cmd "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-ls "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-C"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-d"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-h"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-q"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-R"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-t"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-S"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-r"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-u"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-mkdir "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-moveFromLocal "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("localsrc"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v(". "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("dst"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-moveToLocal "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("localdst"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-mv "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v(". "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("dst"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-put "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-p"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-l"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("localsrc"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v(". "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("dst"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-renameSnapshot "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("snapshotDir"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("oldName"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("newName"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-rm "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-r"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("-R"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-skipTrash"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-rmdir "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("--ignore-fail-on-non-empty"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("dir"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-setfacl "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-R"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("-b"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("-k"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("-m"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("-x "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("acl_spec"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("--set "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("acl_spec"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-setfattr "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),a._v("-n name "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-v value"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" -x name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-setrep "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-R"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-w"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("rep"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-stat "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("format"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-tail "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-f"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("file"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-test -"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("defsz"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-text "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-ignoreCrc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-touchz "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("path"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-usage "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("cmd "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v("."),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n\nGeneric options supported are\n-conf "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("configuration file"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("     specify an application configuration "),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("file")]),a._v("\n-D "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("property"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("value"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("            use value "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("for")]),a._v(" given property\n-fs "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("local"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("namenode:port"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("      specify a namenode\n-jt "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("local"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("resourcemanager:port"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("    specify a ResourceManager\n-files "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("comma separated list of files"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("    specify comma separated files to be copied to the map reduce cluster\n-libjars "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("comma separated list of jars"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("    specify comma separated jar files to include "),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("in")]),a._v(" the classpath.\n-archives "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("comma separated list of archives"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v("    specify comma separated archives to be unarchived on the compute machines.\n\nThe general "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("command")]),a._v(" line syntax is\nbin/hadoop "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v("command")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("genericOptions"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("commandOptions"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n")])])]),s("h2",{attrs:{id:"_1、文件准备"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1、文件准备"}},[a._v("#")]),a._v(" 1、文件准备")]),a._v(" "),s("p",[a._v("        在服务器本地创建 data.txt 文件用于测试，文件的内容如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hello hadoop\n")])])]),s("h2",{attrs:{id:"_2、-appendtofile"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2、-appendtofile"}},[a._v("#")]),a._v(" 2、-appendToFile")]),a._v(" "),s("p",[a._v("        将服务器本地的文件追加到HDFS指定的文件中，如果多次运行相同的参数，则会在 HDFS 的文件中追加多行相同的内容。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -appendToFile data.txt /data/data.txt\n")])])]),s("h2",{attrs:{id:"_3、-cat"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3、-cat"}},[a._v("#")]),a._v(" 3、-cat")]),a._v(" "),s("p",[a._v("        主要用来查看 HDFS 中的非压缩文件的内容。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -cat  /data/data.txt")]),a._v("\nhello hadoop\nhello hadoop\n")])])]),s("h2",{attrs:{id:"_4、-checksum"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4、-checksum"}},[a._v("#")]),a._v(" 4、-checksum")]),a._v(" "),s("p",[a._v("        查看 HDFS 中文件的校验和。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 ~"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -checksum  /data/data.txt")]),a._v("\n/data/data.txt  MD5-of-0MD5-of-512CRC32C        000002000000000000000000c8e21d30c9ed5817cd5ff40768a34389\n")])])]),s("h2",{attrs:{id:"_5、-chgrp"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5、-chgrp"}},[a._v("#")]),a._v(" 5、-chgrp")]),a._v(" "),s("p",[a._v("        改变 HDFS 中文件或目录的所属组，-R 选项可以改变目录下所有子目录的所属组，执行此命令的用户必须是文件或目录的所有者或超级用户。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -chgrp hadoop /data/data.txt\n")])])]),s("h2",{attrs:{id:"_6、-chmod"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_6、-chmod"}},[a._v("#")]),a._v(" 6、-chmod")]),a._v(" "),s("p",[a._v("        修改 HDFS 中文件或目录的访问权限，-R 选项可以修改目录下的所有子目录的访问权限，执行此命令的用户必须是文件或目录的所有者或超级用户。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -chmod "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("700")]),a._v(" /data/data.txt\n")])])]),s("p",[a._v("        此时，data.txt 文件当前的访问权限已经被修改为“ -rwx------”")]),a._v(" "),s("h2",{attrs:{id:"_7、chown"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_7、chown"}},[a._v("#")]),a._v(" 7、chown")]),a._v(" "),s("p",[a._v("        修改文件或目录的所有者，-R选项可以修改目录下所有子目录的所有者，此命令的用户必须是超级用户。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -chown alice:alice /data/data.txt\n")])])]),s("h2",{attrs:{id:"_8、-copyfromlocal"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_8、-copyfromlocal"}},[a._v("#")]),a._v(" 8、-copyFromLocal")]),a._v(" "),s("p",[a._v("        将本地服务器上的文件复制到HDFS中。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -copyFromLocal a.txt /data/\n")])])]),s("h2",{attrs:{id:"_9、-copytolocal"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_9、-copytolocal"}},[a._v("#")]),a._v(" 9、-copyToLocal")]),a._v(" "),s("p",[a._v("        将 HDFS 中的文件复制到服务器本地。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -copyToLocal /data/data.txt /home/hadoop/input\n")])])]),s("h2",{attrs:{id:"_10、-count"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_10、-count"}},[a._v("#")]),a._v(" 10、-count")]),a._v(" "),s("p",[a._v("        显示目录下的子目录数、文件数、占用字节数、所有文件和目录名，-q 选项显示目录和空间的配额信息。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -count /data/")]),a._v("\n           "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),a._v("            "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("9")]),a._v("                "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("456")]),a._v(" /data\n")])])]),s("h2",{attrs:{id:"_11、-cp"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_11、-cp"}},[a._v("#")]),a._v(" 11、-cp")]),a._v(" "),s("p",[a._v("        复制文件或目录，如果源文件或目录有多个，则目标必须为目录。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -cp /data/data.txt /data/data.tmp\n")])])]),s("h2",{attrs:{id:"_12、-createsnapshot"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12、-createsnapshot"}},[a._v("#")]),a._v(" 12、-createSnapshot")]),a._v(" "),s("p",[a._v("        为HDFS中的文件创建快照，实例代码如下：\n        首先在 HDFS 中创建目录 /sn，并将 /sn 目录设置为可快照，如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -mkdir /sn")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfsadmin -allowSnapshot /sn")]),a._v("\nAllowing snaphot on /sn succeeded\n")])])]),s("p",[a._v("        接下来执行创建快照操作，如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -createSnapshot /sn s1")]),a._v("\nCreated snapshot /sn/.snapshot/s1\n")])])]),s("p",[a._v("        说明创建快照成功。")]),a._v(" "),s("h2",{attrs:{id:"_13、-deletesnapshot"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_13、-deletesnapshot"}},[a._v("#")]),a._v(" 13、-deleteSnapshot")]),a._v(" "),s("p",[a._v("        删除 HDFS 中的文件快照，实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -deleteSnapshot /sn sn1\n")])])]),s("p",[a._v("        删除 /sn 目录的快照sn1")]),a._v(" "),s("h2",{attrs:{id:"_14、-df"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_14、-df"}},[a._v("#")]),a._v(" 14、-df")]),a._v(" "),s("p",[a._v("        查看 HDFS 中目录空间的使用情况。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -df -h /data")]),a._v("\nFilesystem             Size    Used  Available  Use%\nhdfs://node01:8020  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("130.1")]),a._v(" G  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("13.7")]),a._v(" G     "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("57.8")]),a._v(" G   "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("11")]),a._v("%\n")])])]),s("h2",{attrs:{id:"_15、-du"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_15、-du"}},[a._v("#")]),a._v(" 15、-du")]),a._v(" "),s("p",[a._v("        查看 HDFS 或目录中的文件大小。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -du -h -s -x /data")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("456")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1.3")]),a._v(" K  /data\n")])])]),s("h2",{attrs:{id:"_16、-expunge"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_16、-expunge"}},[a._v("#")]),a._v(" 16、-expunge")]),a._v(" "),s("p",[a._v("        清空HDFS中的回收站，实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -expunge")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v("/12/27 "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v(":41:48 INFO fs.TrashPolicyDefault: TrashPolicyDefault"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#deleteCheckpoint for trashRoot: hdfs://node01:8020/user/root/.Trash")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v("/12/27 "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v(":41:48 INFO fs.TrashPolicyDefault: TrashPolicyDefault"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#deleteCheckpoint for trashRoot: hdfs://node01:8020/user/root/.Trash")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v("/12/27 "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v(":41:48 INFO fs.TrashPolicyDefault: Deleted trash checkpoint: /user/root/.Trash/201028063715\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v("/12/27 "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v(":41:48 INFO fs.TrashPolicyDefault: Deleted trash checkpoint: /user/root/.Trash/201031181139\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v("/12/27 "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v(":41:48 INFO fs.TrashPolicyDefault: TrashPolicyDefault"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("#createCheckpoint for trashRoot: hdfs://node01:8020/user/root/.Trash")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v("/12/27 "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v(":41:48 INFO fs.TrashPolicyDefault: Created trash checkpoint: /user/root/.Trash/201227204148\n")])])]),s("h2",{attrs:{id:"_17、-find"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_17、-find"}},[a._v("#")]),a._v(" 17、-find")]),a._v(" "),s("p",[a._v("        查找 HDFS 中指定目录下的文件。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -find /data /data/data.txt")]),a._v("\n/data\n/data/a.txt\n/data/data.txt\n")])])]),s("h2",{attrs:{id:"_18、-get"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_18、-get"}},[a._v("#")]),a._v(" 18、-get")]),a._v(" "),s("p",[a._v("        将 HDFS 中的文件复制到本地服务器。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -get /data/data.txt  /home/hadoop/input\n")])])]),s("h2",{attrs:{id:"_19、-getfacl"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_19、-getfacl"}},[a._v("#")]),a._v(" 19、-getfacl")]),a._v(" "),s("p",[a._v("        查看HDFS中指定目录下的文件的访问控制列表，-R 选项可以查看所有子目录下的文件访问控制列表。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -getfacl /data")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# file: /data")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# owner: root")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# group: supergroup")]),a._v("\n")])])]),s("h2",{attrs:{id:"_20、-getfattr"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_20、-getfattr"}},[a._v("#")]),a._v(" 20、-getfattr")]),a._v(" "),s("p",[a._v("        查看 HDFS 上的文件扩展属性信息，-R 选项可以查看当前目录下所有子目录中的文件扩展属性信息或子目录下文件的扩展属性信息。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -getfattr -R -d /data")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# file: /data")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# file: /data/a.txt")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# file: /data/data.txt")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# file: /data/input")]),a._v("\n")])])]),s("h2",{attrs:{id:"_21、-getmerge"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_21、-getmerge"}},[a._v("#")]),a._v(" 21、-getmerge")]),a._v(" "),s("p",[a._v("        将 HDFS 中的多个文件合并为一个文件，复制到本地服务器。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -getmerge /data/a.txt /data/b.txt /home/hadoop/input/data.local\n")])])]),s("h2",{attrs:{id:"_22、-head"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_22、-head"}},[a._v("#")]),a._v(" 22、-head")]),a._v(" "),s("p",[a._v("        以head方式查看 HDFS 中的文件，此命令后面的文件只能为文件，不能为目录，实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -head /data/data.txt")]),a._v("\nhello hadoop\nhello hadoop\n")])])]),s("h2",{attrs:{id:"_23、-help"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_23、-help"}},[a._v("#")]),a._v(" 23、-help")]),a._v(" "),s("p",[a._v("        查看 Hadoop 具体命令的帮助信息。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -help cat")]),a._v("\n-cat "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-ignoreCrc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v(". "),s("span",{pre:!0,attrs:{class:"token builtin class-name"}},[a._v(":")]),a._v("\n  Fetch all files that match the "),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("file")]),a._v(" pattern "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" and display their content on\n  stdout.\n")])])]),s("h2",{attrs:{id:"_24、-ls"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_24、-ls"}},[a._v("#")]),a._v(" 24、-ls")]),a._v(" "),s("p",[a._v("        列出 HDFS 中指定目录下的信息，实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -ls /data")]),a._v("\nFound "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" items\n-rw-r--r--   "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" root supergroup          "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2020")]),a._v("-12-27 "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("20")]),a._v(":11 /data/a.txt\n-rw-r--r--   "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),a._v(" root supergroup         "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("26")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2020")]),a._v("-12-27 "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("18")]),a._v(":59 /data/data.txt\ndrwxr-xr-x   - root supergroup          "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2020")]),a._v("-09-18 "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("19")]),a._v(":16 /data/input\n")])])]),s("h2",{attrs:{id:"_25、-mkdir"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_25、-mkdir"}},[a._v("#")]),a._v(" 25、-mkdir")]),a._v(" "),s("p",[a._v("        在 HDFS 上创建目录，实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -mkdir /test/data\n")])])]),s("h2",{attrs:{id:"_26、-movefromlocal"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_26、-movefromlocal"}},[a._v("#")]),a._v(" 26、-moveFromLocal")]),a._v(" "),s("p",[a._v("        移动本地服务器上的某个文件到 HDFS 中。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -moveFromLocal /home/hadoop/input/data.local /data/\n")])])]),s("h2",{attrs:{id:"_27、-movetolocal"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_27、-movetolocal"}},[a._v("#")]),a._v(" 27、-moveToLocal")]),a._v(" "),s("p",[a._v("        移动 HDFS 中的文件到本地服务器的某个目录下。")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -moveToLocal  /data/data.txt  /home/hadoop/input/\n")])])]),s("blockquote",[s("p",[a._v("注意：| 此命令在 Hadoop3.2.0 版本中尚未实现")])]),a._v(" "),s("h2",{attrs:{id:"_28、-mv"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_28、-mv"}},[a._v("#")]),a._v(" 28、-mv")]),a._v(" "),s("p",[a._v("        移动 HDFS 中的目录到 HDFS 中的另一个目录下。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -mv /data/data.local /test\n")])])]),s("h2",{attrs:{id:"_29、-put"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_29、-put"}},[a._v("#")]),a._v(" 29、-put")]),a._v(" "),s("p",[a._v("        复制本地文件到 HDFS 中的某个目录下。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -put /home/hadoop/input/data.local /data\n")])])]),s("h2",{attrs:{id:"_30、-renamesnapshot"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_30、-renamesnapshot"}},[a._v("#")]),a._v(" 30、-renameSnapshot")]),a._v(" "),s("p",[a._v("        重命名 HDFS 上的文件快照。实例代码如下：\n        首先在 HDFS 中创建目录 /sn，并将 /sn 目录设置为可快照，如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -mkdir /sn")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hdfs dfsadmin -allowSnapshot /sn")]),a._v("\nAllowing snaphot on /sn succeeded\n")])])]),s("p",[a._v("        接下来执行创建快照操作，如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -createSnapshot /sn s1")]),a._v("\nCreated snapshot /sn/.snapshot/s1\n")])])]),s("p",[a._v("        说明创建快照成功。\n        接下来将 /sn 目录的快照名称 sn1 重命名为 sn2，如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -renameSnapshot /sn sn1 sn2\n")])])]),s("h2",{attrs:{id:"_31、-rm"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_31、-rm"}},[a._v("#")]),a._v(" 31、-rm")]),a._v(" "),s("p",[a._v("        删除文件或目录。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -rm /data/data.local\n")])])]),s("h2",{attrs:{id:"_32、-rmkdir"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_32、-rmkdir"}},[a._v("#")]),a._v(" 32、-rmkdir")]),a._v(" "),s("p",[a._v("        删除HDFS上的目录，此目录必须是空目录。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -mkdir /test\n")])])]),s("h2",{attrs:{id:"_33、-setrep"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_33、-setrep"}},[a._v("#")]),a._v(" 33、-setrep")]),a._v(" "),s("p",[a._v("        设置 HDFS 上的文件的目标副本数量，-R 选项可以对子目录逐级进行相同的操作， -w 选项等待副本达到设置值。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -setrep "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),a._v(" /data/data.txt\n")])])]),s("h2",{attrs:{id:"_34、-stat"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_34、-stat"}},[a._v("#")]),a._v(" 34、-stat")]),a._v(" "),s("p",[a._v("        查看 HDFS 上文件或目录的统计信息，以 format 的格式列出。可选的 format 格式如下：")]),a._v(" "),s("ol",[s("li",[a._v("%b：文件所占的块数")]),a._v(" "),s("li",[a._v("%g：文件所属的用户组")]),a._v(" "),s("li",[a._v("%n：文件名")]),a._v(" "),s("li",[a._v("%o：文件块大小")]),a._v(" "),s("li",[a._v("%r：备份数")]),a._v(" "),s("li",[a._v("%u：文件所属用户")]),a._v(" "),s("li",[a._v("%y：文件修改时间")])]),a._v(" "),s("p",[a._v("        实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("$ hadoop fs -stat %b,%g,%n,%o,%r,%u,%y /data\n"),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("0")]),a._v(",hive,data,0,0,hive,2020-11-16 07:54:04\n")])])]),s("h2",{attrs:{id:"_35、-tail"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_35、-tail"}},[a._v("#")]),a._v(" 35、-tail")]),a._v(" "),s("p",[a._v("        显示一个文件的末尾数据，通常是显示文件最后的 1KB 的数据。-f 选项可以监听文件的变化，当有内容追加到文件中时，-f 选项能够实时显示追加的内容。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -tail /data/data.txt")]),a._v("\nhello hadoop\nhello hadoop\n")])])]),s("h2",{attrs:{id:"_36、-test"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_36、-test"}},[a._v("#")]),a._v(" 36、-test")]),a._v(" "),s("p",[a._v("        检测文件的信息，参数选项如下：")]),a._v(" "),s("ol",[s("li",[a._v("-d：如果路径为目录则返回0")]),a._v(" "),s("li",[a._v("-e：如果路径存在则返回0")]),a._v(" "),s("li",[a._v("-f：如果路径为文件则返回0")]),a._v(" "),s("li",[a._v("-s：如果路径中的文件大于0字节则返回0")]),a._v(" "),s("li",[a._v("-w：如果路径存在并且具有写权限则返回0")]),a._v(" "),s("li",[a._v("-r：如果路径存在并且具有读权限则返回0")]),a._v(" "),s("li",[a._v("-z：如果路径中的文件为0字节则返回0，否则返回1")])]),a._v(" "),s("p",[a._v("        实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -test -d /data\n")])])]),s("h2",{attrs:{id:"_37、-text"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_37、-text"}},[a._v("#")]),a._v(" 37、-text")]),a._v(" "),s("p",[a._v("        查看文件内容。text 命令除了能够查看非压缩的文本文件内容之外，也能查看压缩后的文本文件内容；cat命令只能查看非压缩的文本文件内容。实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -text /data/data.txt")]),a._v("\nhello hadoop\nhello hadoop\n")])])]),s("h2",{attrs:{id:"_38、touch"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_38、touch"}},[a._v("#")]),a._v(" 38、touch")]),a._v(" "),s("p",[a._v("        在 HDFS 上创建文件，如果文件不存在则不报错，实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[a._v("hadoop fs -touch /data/data.touch\n")])])]),s("h2",{attrs:{id:"_39、-truncate"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_39、-truncate"}},[a._v("#")]),a._v(" 39、-truncate")]),a._v(" "),s("p",[a._v("        切断 HDFS 上的文件，实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -truncate 26 /data/data.txt")]),a._v("\nTruncate /data/data.txt to length: "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("26")]),a._v("\n")])])]),s("h2",{attrs:{id:"_40、-usage"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_40、-usage"}},[a._v("#")]),a._v(" 40、-usage")]),a._v(" "),s("p",[a._v("        列出指定命令的使用格式，实例代码如下所示：")]),a._v(" "),s("div",{staticClass:"language-bash extra-class"},[s("pre",{pre:!0,attrs:{class:"language-bash"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("root@node01 zwj"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("# hadoop fs -usage cat")]),a._v("\nUsage: hadoop fs "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("generic options"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" -cat "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("-ignoreCrc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("src"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("..")]),a._v(".\n")])])])])}),[],!1,null,null,null);t.default=e.exports}}]);