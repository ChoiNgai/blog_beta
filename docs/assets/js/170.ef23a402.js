(window.webpackJsonp=window.webpackJsonp||[]).push([[170],{538:function(a,t,s){"use strict";s.r(t);var r=s(30),e=Object(r.a)({},(function(){var a=this,t=a.$createElement,s=a._self._c||t;return s("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[s("p",[a._v("        之前分享过一篇博客，👉"),s("a",{attrs:{href:"https://alice.blog.csdn.net/article/details/106337941",target:"_blank",rel:"noopener noreferrer"}},[a._v("不会这20个Spark热门技术点，你敢出去面试大数据吗?"),s("OutboundLink")],1),a._v("，那一篇确实是非常精华，提炼出了非常重要同样非常高频的Spark技术点，也算是收到了一些朋友们的好评。本篇博客，博主打算再出个番外篇，也就是再为大家分享一些Spark面试题，敢问各位准备好了么~")]),a._v(" "),s("p",[s("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200608220400797.jpg?",alt:"在这里插入图片描述"}})]),a._v(" "),s("hr"),a._v(" "),s("h2",{attrs:{id:"_1、spark-application在没有获得足够的资源-job就开始执行了-可能会导致什么问题发生"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1、spark-application在没有获得足够的资源-job就开始执行了-可能会导致什么问题发生"}},[a._v("#")]),a._v(" 1、Spark Application在没有获得足够的资源，job就开始执行了，可能会导致什么问题发生?")]),a._v(" "),s("p",[a._v("        执行该job时候集群资源不足，导致执行job结束也没有分配足够的资源，分配了部分Executor，该job就开始执行task，应该是task的调度线程和Executor资源申请是异步的；如果想等待申请完所有的资源再执行job的：需要将"),s("code",[a._v("spark.scheduler.maxRegisteredResourcesWaitingTime")]),a._v("设置的很大；"),s("code",[a._v("spark.scheduler.minRegisteredResourcesRatio")]),a._v(" 设置为1，但是应该结合实际考虑，否则很容易出现长时间分配不到资源，job一直不能运行的情况。")]),a._v(" "),s("h2",{attrs:{id:"_2、driver的功能是什么"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2、driver的功能是什么"}},[a._v("#")]),a._v(" 2、driver的功能是什么？")]),a._v(" "),s("ul",[s("li",[a._v("一个Spark作业运行时包括一个Driver进程，也是作业的主进程，具有main函数，并且有SparkContext的实例，是程序的人口点；")]),a._v(" "),s("li",[a._v("功能：负责向集群"),s("strong",[a._v("申请资源")]),a._v("，"),s("strong",[a._v("向master注册信息，负责了作业的调度，负责作业的解析、生成Stage并调度Task")]),a._v("到Executor上。包括DAGScheduler，TaskScheduler")])]),a._v(" "),s("h2",{attrs:{id:"_3、spark中work的主要工作是什么"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3、spark中work的主要工作是什么"}},[a._v("#")]),a._v(" 3、Spark中Work的主要工作是什么？")]),a._v(" "),s("p",[a._v("        主要功能：管理当前节点内存，CPU的使用状况，接收master分配过来的资源指令，通过ExecutorRunner启动程序分配任务。")]),a._v(" "),s("p",[a._v("        worker就类似于包工头，管理分配新进程，做计算的服务，相当于process服务。")]),a._v(" "),s("p",[a._v("        需要注意的是：")]),a._v(" "),s("p",[a._v("        1）worker会不会汇报当前信息给master？"),s("strong",[a._v("worker心跳给master主要只有workid，它不会发送资源信息以心跳的方式给master")]),a._v("，master分配的时候就知道work，只有出现故障的时候才会发送资源。")]),a._v(" "),s("p",[a._v("        2）worker不会运行代码，具体运行的是Executor是可以运行具体appliaction写的业务逻辑代码，操作代码的节点，它不会运行程序的代码的。")]),a._v(" "),s("h2",{attrs:{id:"_4、spark为什么比mapreduce快"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4、spark为什么比mapreduce快"}},[a._v("#")]),a._v(" 4、Spark为什么比mapreduce快？")]),a._v(" "),s("ol",[s("li",[a._v("spark是基于内存进行数据处理的，MapReduce是基于磁盘进行数据处理的")]),a._v(" "),s("li",[a._v("spark中具有DAG有向无环图，DAG有向无环图在此过程中减少了shuffle以及落地磁盘的次数")]),a._v(" "),s("li",[s("strong",[a._v("spark是粗粒度资源申请")]),a._v("，也就是当提交spark application的时候，application会将所有的资源申请完毕，如果申请不到资源就等待，如果申请到资源才执行application，task在执行的时候就不需要自己去申请资源，task执行快，当最后一个task执行完之后task才会被释放。而"),s("strong",[a._v("MapReduce是细粒度资源申请")]),a._v("，当提交application的时候，task执行时，自己申请资源，自己释放资源，task执行完毕之后，资源立即会被释放，task执行的慢，application执行的相对比较慢。")])]),a._v(" "),s("h2",{attrs:{id:"_5、mapreduce和spark的都是并行计算-那么他们有什么相同和区别"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5、mapreduce和spark的都是并行计算-那么他们有什么相同和区别"}},[a._v("#")]),a._v(" 5、Mapreduce和Spark的都是并行计算，那么他们有什么相同和区别？")]),a._v(" "),s("ul",[s("li",[a._v("hadoop的一个作业称为job，job里面分为map task和reduce task，每个task都是在自己的进程中运行的，当task结束时，进程也会结束。")]),a._v(" "),s("li",[a._v("spark用户提交的任务成为application，一个application对应一个sparkcontext，app中存在多个job，每触发一次action操作就会产生一个job。这些job可以并行或串行执行，每个job中有多个stage，stage是shuffle过程中DAGSchaduler通过RDD之间的依赖关系划分job而来的，每个stage里面有多个task，组成taskset有TaskSchaduler分发到各个executor中执行，executor的生命周期是和app一样的，即使没有job运行也是存在的，所以task可以快速启动读取内存进行计算。")]),a._v(" "),s("li",[a._v("hadoop的job只有map和reduce操作，表达能力比较欠缺而且在mr过程中会重复的读写hdfs，"),s("strong",[a._v("造成大量的io操作，多个job需要自己管理关系")]),a._v("。 而spark的迭代计算都是在内存中进行的，API中提供了大量的RDD操作如join，groupby等，而且"),s("strong",[a._v("通过DAG图可以实现良好的容错")]),a._v("。")])]),a._v(" "),s("h2",{attrs:{id:"_6、spark应用程序的执行过程是什么"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_6、spark应用程序的执行过程是什么"}},[a._v("#")]),a._v(" 6、Spark应用程序的执行过程是什么？")]),a._v(" "),s("ol",[s("li",[a._v("构建Spark Application的运行环境（启动SparkContext），SparkContext向资源管理器（可以是Standalone、Mesos或YARN）注册并申请运行Executor资源；")]),a._v(" "),s("li",[a._v("资源管理器分配Executor资源并启动StandaloneExecutorBackend，Executor运行情况将随着心跳发送到资源管理器上；")]),a._v(" "),s("li",[a._v("SparkContext构建成DAG图，将DAG图分解成Stage，并把Taskset发送给Task Scheduler。Executor向SparkContext申请Task，Task Scheduler将Task发放给Executor运行同时SparkContext将应用程序代码发放给Executor。")]),a._v(" "),s("li",[a._v("Task在Executor上运行，运行完毕释放所有资源。")])]),a._v(" "),s("h2",{attrs:{id:"_7、spark-on-yarn-cluster-模式下-applicationmaster和driver是在同一个进程么"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_7、spark-on-yarn-cluster-模式下-applicationmaster和driver是在同一个进程么"}},[a._v("#")]),a._v(" 7、spark on yarn Cluster 模式下，ApplicationMaster和driver是在同一个进程么？")]),a._v(" "),s("p",[a._v("        是,driver 位于ApplicationMaster进程中。该进程负责申请资源，还负责监控程序、资源的动态情况。")]),a._v(" "),s("h2",{attrs:{id:"_8、spark-on-yarn-模式有哪些优点"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_8、spark-on-yarn-模式有哪些优点"}},[a._v("#")]),a._v(" 8、Spark on Yarn 模式有哪些优点？")]),a._v(" "),s("ol",[s("li",[a._v("与其他计算框架共享集群资源（eg.Spark框架与MapReduce框架同时运行，如果不用Yarn进行资源分配，MapReduce分到的内存资源会很少，效率低下）；资源按需分配，进而提高集群资源利用等。")]),a._v(" "),s("li",[a._v("相较于Spark自带的Standalone模式，Yarn的资源分配更加细致")]),a._v(" "),s("li",[a._v("Application部署简化，例如Spark，Storm等多种框架的应用由客户端提交后，由Yarn负责资源的管理和调度，利用Container作为资源隔离的单位，以它为单位去使用内存,cpu等。")]),a._v(" "),s("li",[a._v("Yarn通过队列的方式，管理同时运行在Yarn集群中的多个服务，可根据不同类型的应用程序负载情况，调整对应的资源使用量，实现资源弹性管理。")])]),a._v(" "),s("h2",{attrs:{id:"_9、spark中的rdd是什么-有哪些特性"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_9、spark中的rdd是什么-有哪些特性"}},[a._v("#")]),a._v(" 9、spark中的RDD是什么，有哪些特性？")]),a._v(" "),s("p",[a._v("        RDD（Resilient Distributed Dataset）叫做分布式数据集，是spark中最基本的数据抽象，它代表一个不可变，可分区，里面的元素可以并行计算的集合。")]),a._v(" "),s("p",[a._v("        五大特性：")]),a._v(" "),s("ul",[s("li",[a._v("A list of partitions：一个分区列表，RDD中的数据都存储在一个分区列表中")]),a._v(" "),s("li",[a._v("A function for computing each split：作用在每一个分区中的函数")]),a._v(" "),s("li",[a._v("A list of dependencies on other RDDs：一个RDD依赖于其他多个RDD，这个点很重要，RDD的容错机制就是依据这个特性而来的")]),a._v(" "),s("li",[a._v("Optionally,a Partitioner for key-value RDDs(eg:to say that the RDD is hash-partitioned)：可选的，针对于kv类型的RDD才有这个特性，作用是决定了数据的来源以及数据处理后的去向")]),a._v(" "),s("li",[a._v("可选项，数据本地性，数据位置最优")])]),a._v(" "),s("h2",{attrs:{id:"_10、spark如何防止内存溢出"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_10、spark如何防止内存溢出"}},[a._v("#")]),a._v(" 10、spark如何防止内存溢出？")]),a._v(" "),s("p",[s("strong",[a._v("driver端的内存溢出 ：")])]),a._v(" "),s("p",[a._v("        可以增大driver的内存参数：spark.driver.memory (default 1g)")]),a._v(" "),s("p",[s("strong",[a._v("map过程产生大量对象导致内存溢出：")])]),a._v(" "),s("p",[a._v("        具体做法可以在会产生大量对象的map操作之前调用repartition方法，分区成更小的块传入map。")]),a._v(" "),s("p",[s("strong",[a._v("数据不平衡导致内存溢出：")])]),a._v(" "),s("p",[a._v("        数据不平衡除了有可能导致内存溢出外，也有可能导致性能的问题，解决方法和上面说的类似，就是调用repartition重新分区。")]),a._v(" "),s("p",[s("strong",[a._v("shuffle后内存溢出：")])]),a._v(" "),s("p",[a._v("        shuffle内存溢出的情况可以说都是shuffle后，单个文件过大导致的。在Spark中，join，reduceByKey这一类型的过程，都会有shuffle的过程，在shuffle的使用，需要传入一个partitioner，大部分Spark中的shuffle操作，默认的partitioner都是HashPatitioner，默认值是父RDD中最大的分区数,这个参数通过spark.default.parallelism控制(在spark-sql中用spark.sql.shuffle.partitions) ， spark.default.parallelism参数只对HashPartitioner有效，所以如果是别的Partitioner或者自己实现的Partitioner就不能使用spark.default.parallelism这个参数来控制shuffle的并发量了。如果是别的partitioner导致的shuffle内存溢出，就需要从partitioner的代码增加partitions的数量。")]),a._v(" "),s("p",[s("strong",[a._v("standalone模式下资源分配不均匀导致内存溢出：")])]),a._v(" "),s("p",[a._v("        这种情况的解决方法就是同时配置–executor-cores或者spark.executor.cores参数，确保Executor资源分配均匀。使用rdd.persist(StorageLevel.MEMORY_AND_DISK_SER)代替rdd.cache()。")]),a._v(" "),s("blockquote",[s("p",[s("font",{attrs:{color:"black"}},[s("strong",[a._v("rdd.cache")]),a._v("()和"),s("strong",[a._v("rdd.persist")]),a._v("(Storage.MEMORY_ONLY)是等价的，在内存不足的时候rdd.cache()的数据会丢失，再次使用的时候会重算，而rdd.persist(StorageLevel.MEMORY_AND_DISK_SER)在内存不足的时候会存储在磁盘，避免重算，只是消耗点IO时间")])],1)]),a._v(" "),s("h2",{attrs:{id:"_11、spark中cache和persist的区别"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_11、spark中cache和persist的区别"}},[a._v("#")]),a._v(" 11、spark中cache和persist的区别？")]),a._v(" "),s("p",[a._v("        cache：缓存数据，默认是缓存在内存中，其本质还是调用persist。")]),a._v(" "),s("p",[a._v("        persist:缓存数据，有丰富的数据缓存策略。数据可以保存在内存也可以保存在磁盘中，使用的时候指定对应的缓存级别就可以了。")]),a._v(" "),s("h2",{attrs:{id:"_12、spark手写wordcount程序"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_12、spark手写wordcount程序"}},[a._v("#")]),a._v(" 12、Spark手写WordCount程序")]),a._v(" "),s("p",[a._v("        这个常出现在笔试阶段，手写WordCount算是一项基本技能。")]),a._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("//创建SparkConf并设置App名称和master地址")]),a._v("\nval conf"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("new")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("SparkConf")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("setAppName")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("“wc”"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("setMaster")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("“Local"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("”"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("//创建SparkContext，该对象是提交Spark App的入口")]),a._v("\nval sc"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("new")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("SparkContext")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("conf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("//使用sc创建RDD并执行相应的transformation和action")]),a._v("\nval result"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("sc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("textFile")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("“输入文件的路径”"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\nVal rdd2"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("result"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("flatmap")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token parameter"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("split")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("“ ”"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("map")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("_"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("reduceBykey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("_"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v("_"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("saveAsTextFile")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("“输出文件路径”"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[a._v("//关闭链接")]),a._v("\nsc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("stop")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),s("h2",{attrs:{id:"_13、spark中创建rdd的方式总结3种"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_13、spark中创建rdd的方式总结3种"}},[a._v("#")]),a._v(" 13、Spark中创建RDD的方式总结3种")]),a._v(" "),s("p",[a._v("        1、从集合中创建RDD；")]),a._v(" "),s("div",{staticClass:"language-java extra-class"},[s("pre",{pre:!0,attrs:{class:"language-java"}},[s("code",[a._v("val rdd "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" sc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("parallelize")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Array")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\nval rdd "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" sc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("makeRDD")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token class-name"}},[a._v("Array")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("5")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("6")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("7")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("8")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),s("p",[a._v("        2、从外部存储创建RDD；")]),a._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[a._v("val rdd"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" sc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("textFile")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"hdfs://node01:8020/data/test"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),s("p",[a._v("        3、从其他RDD创建。")]),a._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[a._v("val rdd1 "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" sc"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("parallelize")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("Array")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("3")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("4")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\nval rdd2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v("rdd"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("map")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token parameter"}},[a._v("x")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("map")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("_"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("*")]),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),s("h2",{attrs:{id:"_14、常用算子"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_14、常用算子"}},[a._v("#")]),a._v(" 14、常用算子")]),a._v(" "),s("p",[a._v("        这个涉及到的算子就比较多了，感兴趣的朋友可以去看看博主的这两篇博客:")]),a._v(" "),s("p",[s("a",{attrs:{href:"https://blog.csdn.net/weixin_44318830/article/details/104495531",target:"_blank",rel:"noopener noreferrer"}},[a._v("Spark之【RDD编程】详细讲解(No2)——《Transformation转换算子》"),s("OutboundLink")],1)]),a._v(" "),s("p",[s("a",{attrs:{href:"https://blog.csdn.net/weixin_44318830/article/details/104497091",target:"_blank",rel:"noopener noreferrer"}},[a._v("Spark之【RDD编程】详细讲解(No3)——《Action行动算子》"),s("OutboundLink")],1)]),a._v(" "),s("p",[a._v("        绝对不会让你失望的~")]),a._v(" "),s("h2",{attrs:{id:"_15、什么是宽窄依赖"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_15、什么是宽窄依赖"}},[a._v("#")]),a._v(" 15、什么是宽窄依赖")]),a._v(" "),s("p",[a._v("        窄依赖指的是每一个父RDD的Partition最多被子RDD的一个Partition使用。\n        宽依赖指的是多个子RDD的Partition会依赖同一个父RDD的Partition，会引起shuffle。")]),a._v(" "),s("h2",{attrs:{id:"_16、任务划分的几个重要角色"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_16、任务划分的几个重要角色"}},[a._v("#")]),a._v(" 16、任务划分的几个重要角色")]),a._v(" "),s("p",[a._v("        RDD任务切分中间分为：Application、Job、Stage和Task")]),a._v(" "),s("p",[a._v("        1）Application：初始化一个SparkContext即生成一个Application；")]),a._v(" "),s("p",[a._v("        2）Job：一个Action算子就会生成一个Job；")]),a._v(" "),s("p",[a._v("        3）Stage：根据RDD之间的依赖关系的不同将Job划分成不同的Stage，遇到一个宽依赖则划分一个Stage；")]),a._v(" "),s("p",[a._v("        4）Task：Stage是一个TaskSet，将Stage划分的结果发送到不同的Executor执行即为一个Task")]),a._v(" "),s("h2",{attrs:{id:"_17、sparksql中rdd、dataframe、dataset三者的区别与联系"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_17、sparksql中rdd、dataframe、dataset三者的区别与联系"}},[a._v("#")]),a._v(" 17、SparkSQL中RDD、DataFrame、DataSet三者的区别与联系?")]),a._v(" "),s("p",[s("font",{attrs:{color:"blue",size:"5"}},[s("strong",[a._v("RDD")])])],1),a._v(" "),s("p",[a._v("        弹性分布式数据集；不可变、可分区、元素可以并行计算的集合。")]),a._v(" "),s("p",[s("strong",[a._v("优点：")])]),a._v(" "),s("ul",[s("li",[a._v("RDD编译时类型安全：编译时能检查出类型错误；")]),a._v(" "),s("li",[a._v("面向对象的编程风格：直接通过类名点的方式操作数据。")])]),a._v(" "),s("p",[s("strong",[a._v("缺点：")])]),a._v(" "),s("ul",[s("li",[a._v("序列化和反序列化的性能开销很大，大量的网络传输；")]),a._v(" "),s("li",[a._v("构建对象占用了大量的heap堆内存，导致频繁的GC（程序进行GC时，所有任务都是暂停）")])]),a._v(" "),s("p",[s("font",{attrs:{color:"blue",size:"5"}},[s("strong",[a._v("DataFrame")])])],1),a._v(" "),s("p",[a._v("        DataFrame以RDD为基础的分布式数据集。")]),a._v(" "),s("p",[s("strong",[a._v("优点：")])]),a._v(" "),s("ul",[s("li",[a._v("DataFrame带有元数据schema，每一列都带有名称和类型。")]),a._v(" "),s("li",[a._v("DataFrame引入了off-heap，构建对象直接使用操作系统的内存，不会导致频繁GC。")]),a._v(" "),s("li",[a._v("DataFrame可以从很多数据源构建；")]),a._v(" "),s("li",[a._v("DataFrame把内部元素看成Row对象，表示一行行的数据")]),a._v(" "),s("li",[a._v("DataFrame=RDD+schema")])]),a._v(" "),s("p",[s("strong",[a._v("缺点")]),a._v("：")]),a._v(" "),s("ul",[s("li",[a._v("编译时类型不安全；")]),a._v(" "),s("li",[a._v("不具有面向对象编程的风格。")])]),a._v(" "),s("p",[s("font",{attrs:{color:"blue",size:"5"}},[s("strong",[a._v("Dataset")])])],1),a._v(" "),s("p",[a._v("        DataSet包含了DataFrame的功能，Spark2.0中两者统一，DataFrame表示为DataSet[Row]，即DataSet的子集。")]),a._v(" "),s("p",[a._v("        （1）DataSet可以在编译时检查类型；")]),a._v(" "),s("p",[a._v("        （2）并且是面向对象的编程接口。")]),a._v(" "),s("p",[a._v("        （DataSet 结合了 RDD 和 DataFrame 的优点，并带来的一个新的概念 Encoder。当序列化数据时，Encoder 产生字节码与 off-heap 进行交互，能够达到按需访问数据的效果，而不用反序列化整个对象。）。")]),a._v(" "),s("p",[s("font",{attrs:{color:"blue",size:"5"}},[s("strong",[a._v("三者之间的转换：")])])],1),a._v(" "),s("p",[s("img",{attrs:{src:"https://img-blog.csdnimg.cn/20200608231051390.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDMxODgzMA==,size_16,color_FFFFFF,t_70",alt:"在这里插入图片描述"}})]),a._v(" "),s("h2",{attrs:{id:"_18、自定义函数的过程"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_18、自定义函数的过程"}},[a._v("#")]),a._v(" 18、自定义函数的过程")]),a._v(" "),s("p",[a._v("        1）创建DataFrame")]),a._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[a._v("scala"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" val df "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" spark"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("read"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("json")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"/export/spark/examples/people.json"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\ndf"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" org"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("apache"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("spark"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("sql"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("DataFrame "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("[")]),a._v("age"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" bigint"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" string"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("]")]),a._v("\n")])])]),s("p",[a._v("        2）打印数据")]),a._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[a._v("scala"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" df"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("show")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" age"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("   name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("null")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("Michael"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("30")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("   Andy"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("19")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" Justin"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("\n")])])]),s("p",[a._v("        3）注册UDF，功能为在数据前添加字符串")]),a._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[a._v("scala"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" spark"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("udf"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("register")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"addName"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token parameter"}},[a._v("x"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=>")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Name:"')]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v("x"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\nres5"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v(" org"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("apache"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("spark"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("sql"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("expressions"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("UserDefinedFunction "),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("UserDefinedFunction")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("<")]),a._v("function1"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("StringType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("Some")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("List")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("StringType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),s("p",[a._v("        4）创建临时表")]),a._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[a._v("scala"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" df"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("createOrReplaceTempView")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"people"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),s("p",[a._v("        5）应用UDF")]),a._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[a._v("scala"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(">")]),a._v(" spark"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("sql")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Select addName(name), age from people"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("show")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),s("span",{pre:!0,attrs:{class:"token constant"}},[a._v("UDF")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),s("span",{pre:!0,attrs:{class:"token function"}},[a._v("addName")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("name"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" age"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("-")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("--")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("+")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("     Name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v("Michael"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("null")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("        Name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v("Andy"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("30")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("      Name"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v(":")]),a._v("Justin"),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("  "),s("span",{pre:!0,attrs:{class:"token number"}},[a._v("19")]),s("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v("\n")])])])])}),[],!1,null,null,null);t.default=e.exports}}]);