(window.webpackJsonp=window.webpackJsonp||[]).push([[116],{496:function(t,a,s){"use strict";s.r(a);var n=s(30),e=Object(n.a)({},(function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h2",{attrs:{id:"flinksql入门"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#flinksql入门"}},[t._v("#")]),t._v(" FlinkSQL入门")]),t._v(" "),s("hr"),t._v(" "),s("h2",{attrs:{id:"二、flinksql出现的背景"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#二、flinksql出现的背景"}},[t._v("#")]),t._v(" 二、FlinkSQL出现的背景")]),t._v(" "),s("p",[s("font",{attrs:{color:"\tTomato"}},[s("strong",[t._v("Flink SQL 是 Flink 实时计算为简化计算模型，降低用户使用实时计算门槛而设计的一套符合标准 SQL 语义的开发语言。")])])],1),t._v(" "),s("p",[t._v("        自 2015 年开始，阿里巴巴开始调研开源流计算引擎，最终决定基于 Flink 打造新一代计算引擎，针对 Flink 存在的不足进行优化和改进，并且在 2019 年初将最终代码开源，也就是我们熟知的 Blink。Blink 在原来的 Flink 基础上最显著的一个贡献就是 Flink SQL 的实现。")]),t._v(" "),s("p",[t._v("        Flink SQL 是面向用户的 API 层，在我们传统的流式计算领域，比如 "),s("strong",[s("font",{attrs:{color:"BlueViolet"}},[t._v("Storm、Spark Streaming 都会提供一些 Function 或者 Datastream API，用户通过 Java 或 Scala 写业务逻辑，这种方式虽然灵活，但有一些不足，比如具备一定门槛且调优较难")])],1),t._v("，随着版本的不断更新，API 也出现了很多"),s("strong",[t._v("不兼容")]),t._v("的地方。")]),t._v(" "),s("p",[s("img",{attrs:{src:"https://img-blog.csdnimg.cn/20210116105810976.png",alt:""}})]),t._v(" "),s("p",[t._v("​        在这个背景下，毫无疑问，SQL 就成了我们最佳选择，之所以选择将 SQL 作为核心 API，是因为其具有几个非常重要的特点：")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("SQL 属于设定式语言，用户只要表达清楚需求即可，不需要了解具体做法")]),t._v("；")]),t._v(" "),s("li",[s("strong",[t._v("SQL 可优化，内置多种查询优化器，这些查询优化器可为 SQL 翻译出最优执行计划")]),t._v("；")]),t._v(" "),s("li",[s("strong",[t._v("SQL 易于理解，不同行业和领域的人都懂，学习成本较低")]),t._v("；")]),t._v(" "),s("li",[s("strong",[t._v("SQL 非常稳定，在数据库 30 多年的历史中，SQL 本身变化较少")]),t._v("；")]),t._v(" "),s("li",[s("strong",[t._v("流与批的统一，Flink 底层 Runtime 本身就是一个流与批统一的引擎，而 SQL 可以做到 API 层的流与批统一")]),t._v("。")])]),t._v(" "),s("h2",{attrs:{id:"三、整体介绍"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#三、整体介绍"}},[t._v("#")]),t._v(" 三、整体介绍")]),t._v(" "),s("h3",{attrs:{id:"_3-1-什么是-table-api-和-flink-sql"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-什么是-table-api-和-flink-sql"}},[t._v("#")]),t._v(" 3.1 什么是 Table API 和 Flink SQL?")]),t._v(" "),s("p",[t._v("        Flink本身是批流统一的处理框架，所以"),s("strong",[t._v("Table API和SQL，就是批流统一的上层处理API")]),t._v("。目前功能尚未完善，处于活跃的开发阶段。")]),t._v(" "),s("p",[s("strong",[t._v("Table API是一套内嵌在Java和Scala语言中的查询API")]),t._v("，它允许我们以非常直观的方式，组合来自一些关系运算符的查询（比如select、filter和join）。而对于"),s("strong",[t._v("Flink SQL，就是直接可以在代码中写SQL，来实现一些查询（Query）操作")]),t._v("。Flink的SQL支持，基于实现了SQL标准的Apache Calcite（Apache开源SQL解析工具）。")]),t._v(" "),s("p",[t._v("        无论输入是批输入还是流式输入，在这两套API中，指定的查询都具有相同的语义，得到相同的结果。")]),t._v(" "),s("h3",{attrs:{id:"_3-2-需要引入的依赖"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-需要引入的依赖"}},[t._v("#")]),t._v(" 3.2 需要引入的依赖")]),t._v(" "),s("p",[t._v("        Table API 和 SQL 需要引入的依赖有两个："),s("code",[t._v("planner")]),t._v("  和 "),s("code",[t._v("bridge")])]),t._v(" "),s("div",{staticClass:"language-xml extra-class"},[s("pre",{pre:!0,attrs:{class:"language-xml"}},[s("code",[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.flink"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("flink-table-planner_2.11"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("1.10.0"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org.apache.flink"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("groupId")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("flink-table-api-scala-bridge_2.11"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("artifactId")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("1.10.0"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("version")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("dependency")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),s("p",[t._v("        其中：")]),t._v(" "),s("p",[s("strong",[t._v("flink-table-planner")]),t._v("："),s("font",{attrs:{color:"Tomato"}},[s("strong",[t._v("planner计划器，是table API最主要的部分，提供了运行时环境和生成程序执行计划的planner")])]),t._v("；")],1),t._v(" "),s("p",[s("strong",[t._v("flink-table-api-scala-bridge")]),t._v("："),s("font",{attrs:{color:"Tomato"}},[s("strong",[t._v("bridge桥接器，主要负责table API和 DataStream/DataSet API的连接支持，按照语言分java和scala")])]),t._v("；")],1),t._v(" "),s("p",[t._v("        这里的两个依赖，是IDE环境下运行需要添加的；如果是生产环境，lib目录下默认已经有了planner，就只需要有bridge就可以了。")]),t._v(" "),s("p",[t._v("        当然，如果想使用用户自定义函数，或是跟 kafka 做连接，需要有一个SQL client，这个包含在 "),s("code",[t._v("flink-table-common")]),t._v(" 里。\n        ")]),t._v(" "),s("h3",{attrs:{id:"_3-3-两种planner-old-blink-的区别"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-两种planner-old-blink-的区别"}},[t._v("#")]),t._v(" 3.3 两种planner（old & blink）的区别")]),t._v(" "),s("p",[t._v("        1、"),s("strong",[t._v("批流统一：Blink将批处理作业，视为流式处理的特殊情况")]),t._v("。所以，blink不支持表和DataSet之间的转换，批处理作业将不转换为DataSet应用程序，而是跟流处理一样，转换为DataStream程序来处理。")]),t._v(" "),s("p",[t._v("        2、"),s("strong",[t._v("因为批流统一，Blink planner也不支持BatchTableSource，而使用有界的StreamTableSource代替")]),t._v("。")]),t._v(" "),s("p",[t._v("        3、Blink planner只支持全新的目录，不支持已弃用的ExternalCatalog。")]),t._v(" "),s("p",[t._v("        4、旧 planner 和 Blink planner 的FilterableTableSource实现不兼容。旧的planner会把PlannerExpressions下推到filterableTableSource中，而blink planner则会把Expressions下推。")]),t._v(" "),s("p",[t._v("        5、基于字符串的键值配置选项仅适用于Blink planner。")]),t._v(" "),s("p",[t._v("        6、PlannerConfig在两个planner中的实现不同。")]),t._v(" "),s("p",[t._v("        7、Blink planner会将多个sink优化在一个DAG中（仅在TableEnvironment上受支持，而在StreamTableEnvironment上不受支持）。而旧 planner 的优化总是将每一个sink放在一个新的DAG中，其中所有DAG彼此独立。")]),t._v(" "),s("p",[t._v("        8、旧的planner不支持目录统计，而Blink planner支持。")]),t._v(" "),s("h2",{attrs:{id:"四、api-调用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#四、api-调用"}},[t._v("#")]),t._v(" 四、API 调用")]),t._v(" "),s("h3",{attrs:{id:"_4-1-基本程序结构"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-基本程序结构"}},[t._v("#")]),t._v(" 4.1 基本程序结构")]),t._v(" "),s("p",[s("strong",[t._v("Table API 和 SQL 的程序结构，与流式处理的程序结构类似")]),t._v("；也可以近似地认为有这么几步：首先创建执行环境，然后定义source、transform和sink。")]),t._v(" "),s("p",[t._v("        具体操作流程如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" tableEnv "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("     "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建表的执行环境")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建一张表，用于读取数据")]),t._v("\ntableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("connect"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTemporaryTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"inputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 注册一张表，用于把计算结果输出")]),t._v("\ntableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("connect"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTemporaryTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"outputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 通过 Table API 查询算子，得到一张结果表")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" result "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"inputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 通过 SQL查询语句，得到一张结果表")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sqlResult  "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqlQuery"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"SELECT ... FROM inputTable ..."')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 将结果表写入输出表中")]),t._v("\nresult"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("insertInto"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"outputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"_4-2-创建表环境"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-2-创建表环境"}},[t._v("#")]),t._v(" 4.2 创建表环境")]),t._v(" "),s("p",[t._v("        创建表环境最简单的方式，就是基于流处理执行环境，调create方法直接创建：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" tableEnv "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" StreamTableEnvironment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("env"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("        表环境（"),s("strong",[t._v("TableEnvironment")]),t._v("）是flink中集成 Table API & SQL 的"),s("strong",[t._v("核心概念")]),t._v("。它负责:")]),t._v(" "),s("ul",[s("li",[t._v("注册catalog")]),t._v(" "),s("li",[t._v("在内部 catalog 中注册表")]),t._v(" "),s("li",[t._v("执行 SQL 查询")]),t._v(" "),s("li",[t._v("注册用户自定义函数")]),t._v(" "),s("li",[t._v("将 DataStream 或 DataSet 转换为表")]),t._v(" "),s("li",[t._v("保存对 ExecutionEnvironment 或 StreamExecutionEnvironment  的引用")])]),t._v(" "),s("p",[t._v("        在创建TableEnv的时候，可以多传入一个EnvironmentSettings 或者 TableConfig 参数，可以用来配置 TableEnvironment 的一些特性。")]),t._v(" "),s("p",[t._v("        比如，配置老版本的流式查询（Flink-Streaming-Query）：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" settings "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" EnvironmentSettings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("newInstance"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("useOldPlanner"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 使用老版本planner")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inStreamingMode"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 流处理模式")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("build"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" tableEnv "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" StreamTableEnvironment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("env"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" settings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("        基于老版本的批处理环境（Flink-Batch-Query）：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" batchEnv "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ExecutionEnvironment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("getExecutionEnvironment\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" batchTableEnv "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BatchTableEnvironment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("batchEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("        基于 blink 版本的流处理环境（Blink-Streaming-Query）：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" bsSettings "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" EnvironmentSettings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("newInstance"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("useBlinkPlanner"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inStreamingMode"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("build"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" bsTableEnv "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" StreamTableEnvironment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("env"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" bsSettings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("        基于blink版本的批处理环境（Blink-Batch-Query）：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" bbSettings "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" EnvironmentSettings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("newInstance"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("useBlinkPlanner"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inBatchMode"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("build"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" bbTableEnv "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" TableEnvironment"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("create"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("bbSettings"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h3",{attrs:{id:"_4-3-在catalog中注册表"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-在catalog中注册表"}},[t._v("#")]),t._v(" 4.3 在Catalog中注册表")]),t._v(" "),s("h4",{attrs:{id:"_4-3-1-表-table-的概念"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-1-表-table-的概念"}},[t._v("#")]),t._v(" 4.3.1 表(Table)的概念")]),t._v(" "),s("p",[t._v("        TableEnvironment 可以注册目录 Catalog ，并可以基于Catalog注册表。它会维护一个 Catalog-Table 表之间的map。")]),t._v(" "),s("p",[t._v("        表（Table）是由一个“标识符”来指定的，由3部分组成："),s("strong",[t._v("Catalog名、数据库（database）名和对象名（表名")]),t._v("）。如果没有指定目录或数据库，就使用当前的默认值。")]),t._v(" "),s("p",[t._v("        表可以是常规的（Table，表），或者虚拟的（View，视图）。"),s("strong",[t._v("常规表（Table）一般可以用来描述外部数据，比如文件、数据库表或消息队列的数据，也可以直接从 DataStream转换而来。视图可以从现有的表中创建，通常是 table API 或者SQL查询的一个结果")]),t._v("。")]),t._v(" "),s("h4",{attrs:{id:"_4-3-2-连接到文件系统-csv格式"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-2-连接到文件系统-csv格式"}},[t._v("#")]),t._v(" 4.3.2 连接到文件系统（Csv格式）")]),t._v(" "),s("p",[t._v("        连接外部系统在Catalog中注册表，直接调用 "),s("strong",[t._v("tableEnv.connect()")]),t._v(" 就可以，里面参数要传入一个 ConnectorDescriptor ，也就是connector描述器。对于文件系统的 connector 而言，flink内部已经提供了，就叫做"),s("strong",[t._v("FileSystem()")]),t._v("。")]),t._v(" "),s("p",[t._v("        代码如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[t._v("tableEnv\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("connect"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" FileSystem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sensor.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 定义表数据来源，外部连接")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withFormat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" OldCsv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 定义从外部系统读取数据之后的格式化方法")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withSchema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Schema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("STRING"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"timestamp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("BIGINT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temperature"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DOUBLE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 定义表结构")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTemporaryTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"inputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建临时表")]),t._v("\n")])])]),s("p",[t._v("        这是旧版本的csv格式描述器。由于它是非标的，跟外部系统对接并不通用，所以将被弃用，以后会被一个符合RFC-4180标准的新format描述器取代。"),s("strong",[t._v("新的描述器就叫Csv()，但flink没有直接提供，需要引入依赖flink-csv")]),t._v("：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flink"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("groupId"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("flink"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("csv"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("artifactId"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.10")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".0")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("version"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("dependency"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("        代码非常类似，只需要把 withFormat 里的 OldCsv 改成Csv就可以了。")]),t._v(" "),s("h4",{attrs:{id:"_4-3-3-连接到kafka"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-3-3-连接到kafka"}},[t._v("#")]),t._v(" 4.3.3 连接到Kafka")]),t._v(" "),s("p",[t._v("        kafka的连接器 flink-kafka-connector 中，1.10 版本的已经提供了 Table API 的支持。我们可以在 connect方法中直接传入一个叫做Kafka的类，这就是kafka连接器的描述器ConnectorDescriptor。")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[t._v("tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("connect"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Kafka"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0.11"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 定义kafka的版本")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("topic"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sensor"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 定义主题")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"zookeeper.connect"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"localhost:2181"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bootstrap.servers"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"localhost:9092"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withFormat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withSchema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Schema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("STRING"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"timestamp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("BIGINT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temperature"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DOUBLE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTemporaryTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"kafkaInputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("        当然也可以连接到 ElasticSearch、MySql、HBase、Hive等外部系统，实现方式基本上是类似的。感兴趣的 小伙伴可以自行去研究，这里就不详细赘述了。")]),t._v(" "),s("h3",{attrs:{id:"_4-4-表的查询"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-4-表的查询"}},[t._v("#")]),t._v(" 4.4 表的查询")]),t._v(" "),s("p",[t._v("        通过上面的学习，我们已经利用外部系统的连接器connector，我们可以读写数据，并在环境的Catalog中注册表。接下来就可以对表做"),s("strong",[t._v("查询转换")]),t._v("了。")]),t._v(" "),s("p",[t._v("        Flink给我们提供了两种查询方式：Table API和 SQL。")]),t._v(" "),s("h4",{attrs:{id:"_4-4-1-table-api的调用"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-4-1-table-api的调用"}},[t._v("#")]),t._v(" 4.4.1 Table API的调用")]),t._v(" "),s("p",[t._v("        Table API是集成在Scala和Java语言内的查询API。与SQL不同，Table API的查询不会用字符串表示，而是在宿主语言中一步一步调用完成的。")]),t._v(" "),s("p",[s("strong",[t._v("Table API基于代表一张“表”的Table类，并提供一整套操作处理的方法API")]),t._v("。这些方法会返回一个新的Table对象，这个对象就表示对输入表应用转换操作的结果。有些关系型转换操作，可以由多个方法调用组成，构成链式调用结构。例如"),s("code",[t._v("table.select(…).filter(…)")]),t._v("，其中 select（…）表示选择表中指定的字段，filter(…)表示筛选条件。")]),t._v(" "),s("p",[t._v("        代码中的实现如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sensorTable"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Table "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("from"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"inputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" resultTable"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Table "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" senorTable\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id, temperature"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("filter"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"id ='sensor_1'\"")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"_4-4-2-sql查询"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-4-2-sql查询"}},[t._v("#")]),t._v(" 4.4.2 SQL查询")]),t._v(" "),s("p",[s("strong",[t._v("Flink的SQL集成，基于的是ApacheCalcite，它实现了SQL标准")]),t._v("。在Flink中，用常规字符串来定义SQL查询语句。SQL 查询的结果，是一个新的 Table。")]),t._v(" "),s("p",[t._v("        代码实现如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" resultSqlTable"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Table "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqlQuery"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"select id, temperature from inputTable where id ='sensor_1'\"")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("        或者：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" resultSqlTable"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Table "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqlQuery"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v('"""\n    |select id, temperature\n    |from inputTable\n    |where id = \'sensor_1\'\n  """')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stripMargin"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("        当然，也可以加上聚合操作，比如我们统计每个sensor温度数据出现的个数，做个count统计：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" aggResultTable "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sensorTable\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("groupBy"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token symbol"}},[t._v("'id")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'id, '")]),t._v("id"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("count as "),s("span",{pre:!0,attrs:{class:"token symbol"}},[t._v("'count")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("        SQL的实现：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" aggResultSqlTable "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqlQuery"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"select id, count(id) as cnt from inputTable group by id"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("        这里Table API里指定的字段，前面加了一个单引号’，这是Table API中定义的Expression类型的写法，可以很方便地表示一个表中的字段。")]),t._v(" "),s("p",[t._v("        字段可以直接全部用双引号引起来，也可以用"),s("strong",[t._v("半边单引号+字段名")]),t._v("的方式。以后的代码中，一般都用后一种形式。")]),t._v(" "),s("h3",{attrs:{id:"_4-5-将datastream-转换成表"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-5-将datastream-转换成表"}},[t._v("#")]),t._v(" 4.5 将DataStream 转换成表")]),t._v(" "),s("p",[s("font",{attrs:{color:"DeepPink"}},[t._v("Flink允许我们把Table和DataStream做转换")]),t._v("：我们可以基于一个DataStream，先流式地读取数据源，然后map成样例类，再把它转成Table。Table的列字段（column fields），就是样例类里的字段，这样就不用再麻烦地定义schema了。")],1),t._v(" "),s("h4",{attrs:{id:"_4-5-1-代码表达"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-5-1-代码表达"}},[t._v("#")]),t._v(" 4.5.1 代码表达")]),t._v(" "),s("p",[t._v("        代码中实现非常简单，直接用 tableEnv.fromDataStream() 就可以了。默认转换后的 Table schema 和 DataStream 中的字段定义一一对应，也可以单独指定出来。")]),t._v(" "),s("p",[t._v("        这就允许我们更换字段的顺序、重命名，或者只选取某些字段出来，相当于做了一次map操作（或者Table API的 select操作）。")]),t._v(" "),s("p",[t._v("        代码具体如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" inputStream"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" env"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("readTextFile"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sensor.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dataStream"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("SensorReading"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" inputStream\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" dataArray "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" data"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('","')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    SensorReading"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataArray"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataArray"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toLong"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataArray"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("2")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toDouble"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sensorTable"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Table "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fromDataStreama"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("datStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sensorTable2 "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fromDataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'id, '")]),t._v("timestamp as "),s("span",{pre:!0,attrs:{class:"token symbol"}},[t._v("'ts")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"_4-5-2-数据类型与-table-schema的对应"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-5-2-数据类型与-table-schema的对应"}},[t._v("#")]),t._v(" 4.5.2 数据类型与 Table schema的对应")]),t._v(" "),s("p",[t._v("        在上节的例子中，DataStream 中的数据类型，与表的 Schema 之间的对应关系，是按照样例类中的字段名来对应的（name-based mapping），所以还可以用as做重命名。")]),t._v(" "),s("p",[t._v("        另外一种对应方式是，直接按照字段的位置来对应（position-based mapping），对应的过程中，就可以直接指定新的字段名了。")]),t._v(" "),s("p",[t._v("        基于名称的对应：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sensorTable "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fromDataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'timestamp as '")]),t._v("ts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'id as '")]),t._v("myId"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token symbol"}},[t._v("'temperature")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("        基于位置的对应：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sensorTable "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fromDataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'myId, '")]),t._v("ts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("        Flink的 DataStream 和 DataSet API 支持多种类型。")]),t._v(" "),s("p",[t._v("        组合类型，比如元组（内置Scala和Java元组）、POJO、Scala case类和Flink的Row类型等，允许具有多个字段的嵌套数据结构，这些字段可以在Table的表达式中访问。其他类型，则被视为原子类型。")]),t._v(" "),s("p",[t._v("        元组类型和原子类型，一般用位置对应会好一些；如果非要用名称对应，也是可以的：元组类型，默认的名称是 “_1”, “_2”；而原子类型，默认名称是 ”f0”。")]),t._v(" "),s("h3",{attrs:{id:"_4-6-创建临时视图-temporary-view"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-6-创建临时视图-temporary-view"}},[t._v("#")]),t._v(" 4.6 创建临时视图（Temporary View）")]),t._v(" "),s("p",[t._v("        创建临时视图的第一种方式，就是直接从DataStream转换而来。同样，可以直接对应字段转换；也可以在转换的时候，指定相应的字段。")]),t._v(" "),s("p",[t._v("        代码如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[t._v("tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTemporaryView"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sensorView"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ntableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTemporaryView"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sensorView"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'id, '")]),t._v("temperature"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'timestamp as '")]),t._v("ts"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("        另外，当然还可以基于Table创建视图：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[t._v("tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTemporaryView"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sensorView"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" sensorTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("        View和Table的Schema完全相同。事实上，在Table API中，可以认为View 和 Table 是等价的。")]),t._v(" "),s("h3",{attrs:{id:"_4-7-输出表"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-7-输出表"}},[t._v("#")]),t._v(" 4.7 输出表")]),t._v(" "),s("p",[t._v("        表的输出，是通过将数据写入 TableSink 来实现的。"),s("strong",[t._v("TableSink 是一个通用接口，可以支持不同的文件格式、存储数据库和消息队列")]),t._v("。")]),t._v(" "),s("p",[t._v("        具体实现，输出表最直接的方法，就是"),s("strong",[t._v("通过 Table.insertInto() 方法将一个 Table 写入注册过的 TableSink 中")]),t._v("。")]),t._v(" "),s("h4",{attrs:{id:"_4-7-1-输出到文件"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-7-1-输出到文件"}},[t._v("#")]),t._v(" 4.7.1 输出到文件")]),t._v(" "),s("p",[t._v("        代码如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 注册输出表")]),t._v("\ntableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("connect"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" FileSystem"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"…\\\\resources\\\\out.txt"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 定义到文件系统的连接")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withFormat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 定义格式化方法，Csv格式")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withSchema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Schema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("STRING"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DOUBLE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 定义表结构")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTemporaryTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"outputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建临时表")]),t._v("\n\nresultSqlTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("insertInto"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"outputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"_4-7-2-更新模式-update-mode"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-7-2-更新模式-update-mode"}},[t._v("#")]),t._v(" 4.7.2 更新模式（Update Mode）")]),t._v(" "),s("p",[s("font",{attrs:{color:"red"}},[t._v("在流处理过程中，表的处理并不像传统定义的那样简单。")])],1),t._v(" "),s("p",[t._v("        对于流式查询（Streaming Queries），"),s("strong",[t._v("需要声明如何在（动态）表和外部连接器之间执行转换")]),t._v("。与外部系统交换的消息类型，由"),s("font",{attrs:{color:"purple"}},[s("strong",[t._v("更新模式（update mode）")])]),t._v("指定。")],1),t._v(" "),s("p",[t._v("        Flink Table API中的更新模式有以下三种：")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("追加模式（Append Mode）")])])]),t._v(" "),s("p",[t._v("        在追加模式下，表（动态表）和外部连接器只交换插入（Insert）消息。")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("撤回模式（Retract Mode）")])])]),t._v(" "),s("p",[t._v("        在撤回模式下，表和外部连接器交换的是：添加（Add）和撤回（Retract）消息。")]),t._v(" "),s("p",[t._v("        其中：")]),t._v(" "),s("blockquote",[s("ul",[s("li",[s("font",{attrs:{color:"black"}},[s("strong",[t._v("插入（Insert）会被编码为添加消息；")])])],1),t._v(" "),s("li",[s("font",{attrs:{color:"black"}},[s("strong",[t._v("删除（Delete）则编码为撤回消息；")])])],1),t._v(" "),s("li",[s("font",{attrs:{color:"black"}},[s("strong",[t._v("更新（Update）则会编码为，已更新行（上一行）的撤回消息，和更新行（新行）的添加消息。")])])],1)])]),t._v(" "),s("p",[t._v("        在此模式下，不能定义key，这一点跟upsert模式完全不同。")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("Upsert（更新插入）模式")])])]),t._v(" "),s("p",[t._v("        在Upsert模式下，动态表和外部连接器交换Upsert和Delete消息。")]),t._v(" "),s("p",[t._v("        这个模式需要一个唯一的key，通过这个key可以传递更新消息。为了正确应用消息，外部连接器需要知道这个唯一key的属性。")]),t._v(" "),s("blockquote",[s("ul",[s("li",[s("font",{attrs:{color:"black"}},[s("strong",[t._v("插入（Insert）和更新（Update）都被编码为Upsert消息；")])])],1),t._v(" "),s("li",[s("font",{attrs:{color:"black"}},[s("strong",[t._v("删除（Delete）编码为Delete信息")])])],1)])]),t._v(" "),s("p",[t._v("        这种模式和 Retract 模式的主要区别在于，Update操作是用单个消息编码的，所以效率会更高。")]),t._v(" "),s("h4",{attrs:{id:"_4-7-3-输出到kafka"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-7-3-输出到kafka"}},[t._v("#")]),t._v(" 4.7.3 输出到Kafka")]),t._v(" "),s("p",[t._v("        除了输出到文件，也可以输出到Kafka。我们可以结合前面Kafka作为输入数据，构建数据管道，kafka进，kafka出。")]),t._v(" "),s("p",[t._v("        代码如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 输出到 kafka")]),t._v("\ntableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("connect"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Kafka"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"0.11"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("topic"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sinkTest"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"zookeeper.connect"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"localhost:2181"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("property"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"bootstrap.servers"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"localhost:9092"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withFormat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Csv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withSchema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Schema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("STRING"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("DOUBLE"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTemporaryTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"kafkaOutputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nresultTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("insertInto"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"kafkaOutputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"_4-7-4-输出到elasticsearch"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-7-4-输出到elasticsearch"}},[t._v("#")]),t._v(" 4.7.4 输出到ElasticSearch")]),t._v(" "),s("p",[t._v("        ElasticSearch的connector可以在upsert（update+insert，更新插入）模式下操作，这样就可以使用Query定义的键（key）与外部系统交换UPSERT/DELETE消息。")]),t._v(" "),s("p",[t._v("        另外，对于“仅追加”（append-only）的查询，connector还可以在 append 模式下操作，这样就可以与外部系统只交换 insert 消息。")]),t._v(" "),s("p",[t._v("        es目前支持的数据格式，只有Json，而 flink 本身并没有对应的支持，所以还需要引入依赖：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flink"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("groupId"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("flink"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("json"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("artifactId"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.10")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".0")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("version"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("dependency"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("        代码实现如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 输出到es")]),t._v("\ntableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("connect"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Elasticsearch"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"6"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("host"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"localhost"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("9200")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sensor"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("documentType"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"temp"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("inUpsertMode"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("           "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 指定是 Upsert 模式")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withFormat"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Json"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("withSchema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" Schema"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"id"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("STRING"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("field"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"count"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" DataTypes"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("BIGINT"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createTemporaryTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"esOutputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\naggResultTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("insertInto"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"esOutputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"_4-7-5-输出到mysql"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-7-5-输出到mysql"}},[t._v("#")]),t._v(" 4.7.5 输出到MySql")]),t._v(" "),s("p",[t._v("        Flink专门为Table API的jdbc连接提供了flink-jdbc连接器，我们需要先引入依赖：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("dependency"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("groupId"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("org"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flink"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("groupId"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("artifactId"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("flink"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),t._v("jdbc_2"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("11")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("artifactId"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token generics"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("version"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("1.10")]),s("span",{pre:!0,attrs:{class:"token number"}},[t._v(".0")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("version"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("dependency"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v("\n")])])]),s("p",[t._v("        jdbc连接的代码实现比较特殊，因为没有对应的java/scala类实现 "),s("code",[t._v("ConnectorDescriptor")]),t._v("，所以不能直接 "),s("code",[t._v("tableEnv.connect()")]),t._v("。不过Flink SQL留下了执行DDL的接口："),s("code",[t._v("tableEnv.sqlUpdate()")])]),t._v(" "),s("p",[t._v("        对于jdbc的创建表操作，天生就适合直接写DDL来实现，所以我们的代码可以这样写：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 输出到 Mysql")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" sinkDDL"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token triple-quoted-string string"}},[t._v("\"\"\"\n    |create table jdbcOutputTable (\n    |  id varchar(20) not null,\n    |  cnt bigint not null\n    |) with (\n    |  'connector.type' = 'jdbc',\n    |  'connector.url' = 'jdbc:mysql://localhost:3306/test',\n    |  'connector.table' = 'sensor_count',\n    |  'connector.driver' = 'com.mysql.jdbc.Driver',\n    |  'connector.username' = 'root',\n    |  'connector.password' = '123456'\n    |)\n  \"\"\"")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("stripMargin\n\ntableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sqlUpdate"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sinkDDL"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\naggResultSqlTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("insertInto"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jdbcOutputTable"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("h4",{attrs:{id:"_4-7-6-将表转换成datastream"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-7-6-将表转换成datastream"}},[t._v("#")]),t._v(" 4.7.6 将表转换成DataStream")]),t._v(" "),s("p",[s("strong",[t._v("表可以转换为DataStream或DataSet")]),t._v("。这样，自定义流处理或批处理程序就可以继续在 Table API或SQL查询的结果上运行了。")]),t._v(" "),s("p",[s("strong",[t._v("将表转换为DataStream或DataSet时，需要指定生成的数据类型")]),t._v("，即要将表的每一行转换成的数据类型。通常，"),s("strong",[t._v("最方便的转换类型就是Row")]),t._v("。当然，因为结果的所有字段类型都是明确的，我们也经常会用元组类型来表示。")]),t._v(" "),s("p",[t._v("        表作为流式查询的结果，是"),s("strong",[t._v("动态更新")]),t._v("的。所以，将这种动态查询转换成的数据流，同样需要对表的更新操作进行编码，进而有不同的转换模式。")]),t._v(" "),s("p",[t._v("        Table API 中表到 DataStream 有两种模式：")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("追加模式（Append Mode）")])])]),t._v(" "),s("p",[t._v("        用于表只会被插入（Insert）操作更改的场景")]),t._v(" "),s("ul",[s("li",[s("strong",[t._v("撤回模式（Retract Mode）")])])]),t._v(" "),s("p",[t._v("        用于任何场景。有些类似于更新模式中Retract模式，它只有 Insert 和 Delete 两类操作。")]),t._v(" "),s("p",[s("font",{attrs:{color:"DarkOrchid"}},[t._v("得到的数据会增加一个Boolean类型的标识位（返回的第一个字段），用它来表示到底是新增的数据（Insert），还是被删除的数据（老数据， Delete）")]),t._v("。")],1),t._v(" "),s("p",[t._v("        代码实现如下：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" resultStream"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Row"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toAppendStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Row"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resultTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" aggResultStream"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" DataStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Boolean")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" \ntableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("toRetractStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("Long")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("aggResultTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nresultStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"result"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\naggResultStream"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("print"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"aggResult"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[s("font",{attrs:{color:"HotPink"}},[t._v("所以，没有经过groupby之类聚合操作，可以直接用 toAppendStream 来转换；而如果经过了聚合，有更新操作，一般就必须用 toRetractDstream。\n")])],1),t._v(" "),s("h4",{attrs:{id:"_4-7-7-query的解释和执行"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-7-7-query的解释和执行"}},[t._v("#")]),t._v(" 4.7.7 Query的解释和执行")]),t._v(" "),s("p",[t._v("        Table API提供了一种机制来解释（Explain）"),s("strong",[t._v("计算表的逻辑和优化查询计划")]),t._v("。这是通过TableEnvironment.explain（table）方法或TableEnvironment.explain（）方法完成的。")]),t._v(" "),s("p",[t._v("        explain方法会返回一个字符串，描述三个计划：")]),t._v(" "),s("ul",[s("li",[t._v("未优化的逻辑查询计划")]),t._v(" "),s("li",[t._v("优化后的逻辑查询计划")]),t._v(" "),s("li",[t._v("实际执行计划")])]),t._v(" "),s("p",[t._v("        我们可以在代码中查看执行计划：")]),t._v(" "),s("div",{staticClass:"language-scala extra-class"},[s("pre",{pre:!0,attrs:{class:"language-scala"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" explaination"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("String")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tableEnv"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("explain"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("resultTable"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nprintln"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("explaination"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("p",[t._v("        Query的解释和执行过程，老planner和 blink planner 大体是一致的，又有所不同。整体来讲，Query都会表示成一个逻辑查询计划，然后分两步解释：")]),t._v(" "),s("ol",[s("li",[t._v("优化查询计划")]),t._v(" "),s("li",[t._v("解释成 DataStream 或者 DataSet程序")])]),t._v(" "),s("p",[t._v("        而 Blink 版本是批流统一的，所以所有的Query，只会被解释成DataStream程序；另外在批处理环境 TableEnvironment 下，Blink版本要到 "),s("strong",[t._v("tableEnv.execute()")]),t._v(" 执行调用才开始解释。\n        ")]),t._v(" "),s("p",[t._v("![](https://img-blog.csdnimg.cn/20210116195814196.jpg?,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDMxODgzMA==,size_16,color_FFFFFF,t_70#pic_center =300x250)")]),t._v(" "),s("h2",{attrs:{id:"ref"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#ref"}},[t._v("#")]),t._v(" Ref")]),t._v(" "),s("blockquote",[s("p",[t._v("1、http://www.atguigu.com/"),s("br"),t._v("\n2、https://www.bilibili.com/video/BV12k4y1z7LM?from=search&seid=953051020130358915\n3、https://blog.csdn.net/u013411339/article/details/93267838")])])])}),[],!1,null,null,null);a.default=e.exports}}]);