(window.webpackJsonp=window.webpackJsonp||[]).push([[33],{424:function(t,s,a){"use strict";a.r(s);var n=a(30),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"hive窗口函数总结与实践"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#hive窗口函数总结与实践"}},[t._v("#")]),t._v(" Hive窗口函数总结与实践")]),t._v(" "),a("h2",{attrs:{id:"一、简介"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一、简介"}},[t._v("#")]),t._v(" 一、简介")]),t._v(" "),a("p",[t._v("本文主要介绍Hive中的窗口函数，Hive中的窗口函数和SQL中的窗口函数相类似，都是用来做一些数据分析类的工作，一般用于olap分析（在线分析处理）。")]),t._v(" "),a("h2",{attrs:{id:"二、概念"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二、概念"}},[t._v("#")]),t._v(" 二、概念")]),t._v(" "),a("p",[t._v("我们都知道在sql中有一类函数叫做聚合函数，例如"),a("code",[t._v("sum()、avg()、max()")]),t._v("等等，这类函数可以将多行数据按照规则聚集为一行，一般来讲聚集后的行数是要少于聚集前的行数的，但是有时我们想要既显示聚集前的数据，又要显示聚集后的数据，这时我们便引入了窗口函数。")]),t._v(" "),a("p",[a("strong",[t._v("「在深入研究Over字句之前，一定要注意：在SQL处理中，窗口函数都是最后一步执行，而且仅位于Order by字句之前。」")])]),t._v(" "),a("h2",{attrs:{id:"三、数据准备"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#三、数据准备"}},[t._v("#")]),t._v(" 三、数据准备")]),t._v(" "),a("p",[t._v("我们准备一张order表，字段分别为name，orderdate，cost，数据内容如下：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("jack 2015-04-03 23\njack 2015-01-01 10\ntony 2015-01-02 15\njack 2015-02-03 23\ntony 2015-01-04 29\njack 2015-01-05 46\njack 2015-04-06 42\ntony 2015-01-07 50\njack 2015-01-08 55\nmart 2015-04-08 62\nmart 2015-04-09 68\nneil 2015-05-10 12\nmart 2015-04-11 75\nneil 2015-06-12 80\nmart 2015-04-13 94\n")])])]),a("p",[t._v("在hive中建立一张表order,将数据插入进去。")]),t._v(" "),a("h2",{attrs:{id:"四、聚合函数-over"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#四、聚合函数-over"}},[t._v("#")]),t._v(" 四、聚合函数+over()")]),t._v(" "),a("p",[t._v("假如说我们想要查询在2015年4月份购买过的顾客及总人数，我们便可以使用窗口函数去去实现。"),a("code",[t._v("select name,count(*) over() from order where substring(orderdate,1,7)='2015-04';")]),t._v("得到结果如下："),a("code",[t._v("mart 6mart 6mart 6mart 6jack 6jack 6")]),t._v("可见其实在2015年4月一共有5次购买记录，mart购买了4次，jack购买了2次。事实上，大多数情况下，我们是只看去重后的结果的。针对于这种情况，我们想对代码改进，进行去重，该怎么办呢 😉")]),t._v(" "),a("p",[t._v("第一种方式： "),a("strong",[t._v("「group by」")])]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" j"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("j"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("e "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" e "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" substring"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2015-04'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" j \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("group")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" j"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("j"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("e"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("结果如下：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("jack 6\nmart 6\n")])])]),a("p",[t._v("第二种方式："),a("strong",[t._v("「distinct」")])]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("distinct")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("count")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("where")]),t._v(" substring"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("7")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'2015-04'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("结果如下：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("jack 2\nmart 2\n")])])]),a("h2",{attrs:{id:"五、partition-by-子句"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#五、partition-by-子句"}},[t._v("#")]),t._v(" 五、partition by 子句")]),t._v(" "),a("p",[t._v("Over子句之后第一个提到的就是**「Partition By」"),a("strong",[t._v("。Partition By子句也可以称为")]),t._v("「查询分区子句」**，非常类似于Group By，都是将数据按照边界值分组，而Over之前的函数在每一个分组之内进行，如果超出了分组，则函数会重新计算。")]),t._v(" "),a("p",[t._v("实例")]),t._v(" "),a("p",[t._v("我们想要去看顾客的购买明细及月购买总额，可以执行如下的sql。")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("month")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v("\n")])])]),a("p",[t._v("结果如下：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("tony 2015-01-07 50 205\njack 2015-01-01 10 205\njack 2015-01-05 46 205\ntony 2015-01-04 29 205\ntony 2015-01-02 15 205\njack 2015-01-08 55 205\njack 2015-02-03 23 23\nmart 2015-04-13 94 364\nmart 2015-04-11 75 364\nmart 2015-04-09 68 364\nmart 2015-04-08 62 364\njack 2015-04-06 42 364\njack 2015-04-03 23 364\nneil 2015-05-10 12 12\nneil 2015-06-12 80 80\n")])])]),a("p",[t._v("这里我们可以看到数据已经完全按照月份进行聚合。")]),t._v(" "),a("h2",{attrs:{id:"六、order-by-子句"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#六、order-by-子句"}},[t._v("#")]),t._v(" 六、order by 子句")]),t._v(" "),a("p",[t._v("上述的场景，假如我们想要将cost按照月进行累加，这时我们引入order by子句。")]),t._v(" "),a("p",[t._v("order by子句会让输入的数据强制排序（窗口函数是SQL语句最后执行的函数，因此可以把SQL结果集想象成输入数据）。Order By子句对于诸如"),a("code",[t._v("Row_Number()")]),t._v("，"),a("code",[t._v("Lead()")]),t._v("，"),a("code",[t._v("LAG()")]),t._v("等函数是必须的，因为如果数据无序，这些函数的结果就没有任何意义。因此如果有了Order By子句，则"),a("code",[t._v("Count()")]),t._v("，"),a("code",[t._v("Min()")]),t._v("等计算出来的结果就没有任何意义。")]),t._v(" "),a("p",[t._v("我们在上面的代码中加入order by")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("select name,orderdate,cost,sum(cost) over(partition by month(orderdate) order by orderdate) \nfrom order;\n")])])]),a("p",[t._v("结果如下：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("jack 2015-01-01 10 10         // 10\ntony 2015-01-02 15 25         // 10+15\ntony 2015-01-04 29 54         // 25+29\njack 2015-01-05 46 100\ntony 2015-01-07 50 150\njack 2015-01-08 55 205\njack 2015-02-03 23 23\njack 2015-04-03 23 23\njack 2015-04-06 42 65\nmart 2015-04-08 62 127\nmart 2015-04-09 68 195\nmart 2015-04-11 75 270\nmart 2015-04-13 94 364\nneil 2015-05-10 12 12\nneil 2015-06-12 80 80\n")])])]),a("h2",{attrs:{id:"七、window-子句"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#七、window-子句"}},[t._v("#")]),t._v(" 七、window 子句")]),t._v(" "),a("p",[t._v("我们在上面已经通过使用partition by子句将数据进行了分组的处理，如果我们想要更细粒度的划分，我们就要引入window子句了。")]),t._v(" "),a("p",[t._v("我们首先要理解两个概念：")]),t._v(" "),a("ul",[a("li",[t._v("如果只使用partition by子句，未指定order by的话，我们的聚合是分组内的聚合。")]),t._v(" "),a("li",[t._v("使用了order by子句，未使用window子句的情况下，默认从起点到当前行。")])]),t._v(" "),a("p",[t._v("当同一个select查询中存在多个窗口函数时，他们相互之间是没有影响的，每个窗口函数应用自己的规则。")]),t._v(" "),a("p",[a("strong",[t._v("「window子句」")]),t._v("：")]),t._v(" "),a("ul",[a("li",[t._v("PRECEDING：往前")]),t._v(" "),a("li",[t._v("FOLLOWING：往后")]),t._v(" "),a("li",[t._v("CURRENT ROW：当前行")]),t._v(" "),a("li",[t._v("UNBOUNDED：起点，UNBOUNDED PRECEDING 表示从前面的起点， UNBOUNDED FOLLOWING：表示到后面的终点")])]),t._v(" "),a("p",[t._v("我们按照name进行分区,按照购物时间进行排序，做cost的累加。如下我们结合使用window子句进行查询")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" fullagg"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--所有行相加")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" fullaggbyname"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--按name分组，组内数据相加")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" fabno"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--按name分组，组内数据累加 ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" orderdate "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("between")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("unbounded")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("preceding")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("current")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("row")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" mw1   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--和fabno一样,由最前面的起点到当前行的聚合 ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" orderdate "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("between")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("preceding")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("current")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("row")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" mw2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--当前行和前面一行做聚合 ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" orderdate "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("between")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("preceding")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("following")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" mw3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--当前行和前边一行及后面一行 ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" orderdate "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("rows")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("between")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("current")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("row")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("and")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("unbounded")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("following")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" mw4  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("--当前行及后面所有行 ")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" \n")])])]),a("p",[t._v("结果如下：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("jack 2015-01-01 10 684 199 10 10 10 56 199\njack 2015-01-05 46 684 199 56 56 56 111 189\njack 2015-01-08 55 684 199 111 111 101 124 143\njack 2015-02-03 23 684 199 134 134 78 101 88\njack 2015-04-03 23 684 199 157 157 46 88 65\njack 2015-04-06 42 684 199 199 199 65 65 42\nmart 2015-04-08 62 684 299 62 62 62 130 299\nmart 2015-04-09 68 684 299 130 130 130 205 237\nmart 2015-04-11 75 684 299 205 205 143 237 169\nmart 2015-04-13 94 684 299 299 299 169 169 94\nneil 2015-05-10 12 684 92 12 12 12 92 92\nneil 2015-06-12 80 684 92 92 92 92 92 80\ntony 2015-01-02 15 684 94 15 15 15 44 94\ntony 2015-01-04 29 684 94 44 44 44 94 79\ntony 2015-01-07 50 684 94 94 94 79 79 50\n")])])]),a("h2",{attrs:{id:"八、窗口函数中的序列函数"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#八、窗口函数中的序列函数"}},[t._v("#")]),t._v(" 八、窗口函数中的序列函数")]),t._v(" "),a("p",[t._v("主要序列函数是不支持window子句的。")]),t._v(" "),a("p",[t._v("hive中常用的序列函数有下面几个😀：")]),t._v(" "),a("h3",{attrs:{id:"ntile"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ntile"}},[t._v("#")]),t._v(" ntile")]),t._v(" "),a("p",[t._v("NTILE(n)，用于将分组数据按照顺序切分成n片，返回当前切片值NTILE不支持ROWS BETWEEN， 比如 NTILE(2) OVER(PARTITION BY cookieid ORDER BY createtime ROWS BETWEEN 3 PRECEDING - AND CURRENT ROW)如果切片不均匀，默认增加第一个切片的分布这个函数用什么应用场景呢?假如我们想要每位顾客购买金额前1/3的交易记录,我们便可以使用这个函数。")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n       ntile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" sample1 "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 全局数据切片")]),t._v("\n       ntile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 按照name进行分组,在分组内将数据切成3份")]),t._v("\n       ntile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 全局按照cost升序排列,数据切成3份")]),t._v("\n       ntile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("3")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" cost "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("-- 按照name分组，在分组内按照cost升序排列,数据切成3份")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v("\n")])])]),a("p",[t._v("得到的数据如下：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("jack 2015-01-01 10 3 1 1 1\njack 2015-02-03 23 3 2 1 1\njack 2015-04-03 23 3 3 1 2\njack 2015-04-06 42 2 1 2 2\njack 2015-01-05 46 2 3 2 3\njack 2015-01-08 55 2 2 2 3\nmart 2015-04-08 62 2 1 3 1\nmart 2015-04-09 68 1 2 3 1\nmart 2015-04-11 75 1 3 3 2\nmart 2015-04-13 94 1 1 3 3\nneil 2015-05-10 12 1 2 1 1\nneil 2015-06-12 80 1 1 3 2\ntony 2015-01-02 15 3 2 1 1\ntony 2015-01-04 29 3 1 2 2\ntony 2015-01-07 50 2 3 2 3\n")])])]),a("p",[t._v("如上述数据，我们去sample4 = 1的那部分数据就是我们要的结果")]),t._v(" "),a("h3",{attrs:{id:"row-number"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#row-number"}},[t._v("#")]),t._v(" row_number")]),t._v(" "),a("p",[t._v("用途非常广泛，排序最好用它，它会为查询出来的每一行记录生成一个序号，依次排序且不会重复，注意使用row_number函数时必须要用over子句选择对某一列进行排序才能生成序号。rank函数用于返回结果集的分区内每行的排名，行的排名是相关行之前的排名数加一。简单来说rank函数就是对查询出来的记录进行排名，与row_number函数不同的是，rank函数考虑到了over子句中排序字段值相同的情况，如果使用rank函数来生成序号，over子句中排序字段值相同的序号是一样的，后面字段值不相同的序号将跳过相同的排名号排下一个，也就是相关行之前的排名数加一，可以理解为根据当前的记录数生成序号，后面的记录依此类推。dense_rank函数的功能与rank函数类似，dense_rank函数在生成序号时是连续的，而rank函数生成的序号有可能不连续。dense_rank函数出现相同排名时，将不跳过相同排名号，rank值紧接上一次的rank值。在各个分组内，rank()是跳跃排序，有两个第一名时接下来就是第三名，dense_rank()是连续排序，有两个第一名时仍然跟着第二名。这三个窗口函数的使用场景非常多"),a("code",[t._v("row_number()")]),t._v("：从1开始，按照顺序，生成分组内记录的序列，row_number()的值不会存在重复，当排序的值相同时，按照表中记录的顺序进行排列"),a("code",[t._v("rank()")]),t._v(" ：生成数据项在分组中的排名，排名相等会在名次中**「留下空位」"),a("strong",[a("code",[t._v("dense_rank()")]),t._v(" ：生成数据项在分组中的排名，排名相等会在名次中")]),t._v("「不会留下空位」****「注意：rank和dense_rank的区别在于排名相等时会不会留下空位」**")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\nrow_number"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" rn1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\nrank"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" rn2"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\ndense_rank"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" rn3\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[t._v("得到结果：")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("jack 2015-01-01 10 1 1 1\njack 2015-02-03 23 2 2 2\njack 2015-04-03 23 3 2 2\njack 2015-04-06 42 4 4 3\njack 2015-01-05 46 5 5 4\njack 2015-01-08 55 6 6 5\nmart 2015-04-08 62 1 1 1\nmart 2015-04-09 68 2 2 2\nmart 2015-04-11 75 3 3 3\nmart 2015-04-13 94 4 4 4\nneil 2015-05-10 12 1 1 1\nneil 2015-06-12 80 2 2 2\ntony 2015-01-02 15 1 1 1\ntony 2015-01-04 29 2 2 2\ntony 2015-01-07 50 3 3 3\n")])])]),a("h3",{attrs:{id:"lag-和-lead"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#lag-和-lead"}},[t._v("#")]),t._v(" lag 和 lead")]),t._v(" "),a("p",[t._v("这两个函数为常用的窗口函数,可以返回上下数据行的数据. 以我们的订单表为例,假如我们想要查看顾客上次的购买时间可以这样去查询")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[t._v("hive"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("lag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'1996-09-09'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v("  orderdate "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" time1 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("lag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" orderdate "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" time2 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),a("p",[a("img",{attrs:{src:"https://mmbiz.qpic.cn/mmbiz_png/zWSuIP8rdu0KbLSZGdgjMCdyFeFiaKXqp2bmzkAvH9R24ytIVrtnbnEYgujjrGRDCbVvHZOE249MlMbSFPMoHJA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1",alt:"图片"}}),t._v("time1取的为按照name进行分组，分组内升序排列,取上一行数据的值。")]),t._v(" "),a("p",[t._v("time2取的为按照name进行分组，分组内升序排列,取上面4行的数据的值，注意当lag函数未设置行数值时,默认为1行.设定取不到时的默认值时，取null值。")]),t._v(" "),a("p",[t._v("lead函数与lag函数方向相反，取向下的数据，这里我就不再举例辣😂。")]),t._v(" "),a("h3",{attrs:{id:"first-value-和-last-value"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#first-value-和-last-value"}},[t._v("#")]),t._v(" first_value 和 last_value")]),t._v(" "),a("p",[t._v("first_value取分组内排序后，截止到当前行，第一个值 last_value取分组内排序后，截止到当前行，最后一个值")]),t._v(" "),a("div",{staticClass:"language-sql extra-class"},[a("pre",{pre:!0,attrs:{class:"language-sql"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("select")]),t._v(" name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("cost"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\nfirst_value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" time1"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\nlast_value"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("over")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("partition")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" name "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("by")]),t._v(" orderdate"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" time2\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("order")]),t._v("\n")])])]),a("p",[t._v("查询结果如下:")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("name    orderdate   cost    time1   time2\njack    2015-01-01  10  2015-01-01  2015-01-01\njack    2015-01-05  46  2015-01-01  2015-01-05\njack    2015-01-08  55  2015-01-01  2015-01-08\njack    2015-02-03  23  2015-01-01  2015-02-03\njack    2015-04-06  42  2015-01-01  2015-04-06\nmart    2015-04-08  62  2015-04-08  2015-04-08\nmart    2015-04-09  68  2015-04-08  2015-04-09\nmart    2015-04-11  75  2015-04-08  2015-04-11\nmart    2015-04-13  94  2015-04-08  2015-04-13\nneil    2015-05-10  12  2015-05-10  2015-05-10\nneil    2015-06-12  80  2015-05-10  2015-06-12\ntony    2015-01-02  15  2015-01-02  2015-01-02\ntony    2015-01-04  29  2015-01-02  2015-01-04\ntony    2015-01-07  50  2015-01-02  2015-01-07\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);